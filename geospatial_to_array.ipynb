{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "from typing import Tuple, Dict, Any, List\n",
    "import os\n",
    "from tkinter import Tk, filedialog, simpledialog, Toplevel, Button, Checkbutton, IntVar, Label, Frame\n",
    "from tkinter.filedialog import askopenfilenames, askdirectory, asksaveasfilename\n",
    "\n",
    "import cupy as cp\n",
    "import geopandas as gpd\n",
    "import hvplot.xarray\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.widgets import Slider\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.features import rasterize\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from scipy import stats\n",
    "from scipy.ndimage import generic_filter\n",
    "from scipy.stats import mode\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import box\n",
    "import xarray as xr\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import easygui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE GRID SIZE (from mask short edge)\n",
    "\n",
    "# Function to compute grid size based on the mask file\n",
    "def compute_grid_size(geojson_file: str, short_edge_cells: int = 20) -> Tuple[int, int]:\n",
    "    # Read the GeoJSON file using GeoPandas\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    \n",
    "    # Get the bounding box of the masking region\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    \n",
    "    # Calculate width and height of the bounding box\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    # Determine which is the short and long edge\n",
    "    if width < height:\n",
    "        short_edge = width\n",
    "        long_edge = height\n",
    "        orientation = 'portrait'\n",
    "    else:\n",
    "        short_edge = height\n",
    "        long_edge = width\n",
    "        orientation = 'landscape'\n",
    "\n",
    "    # Compute the aspect ratio\n",
    "    aspect_ratio = long_edge / short_edge\n",
    "\n",
    "    # Compute the number of cells for the long edge\n",
    "    long_edge_cells = int(short_edge_cells * aspect_ratio)\n",
    "\n",
    "    # Determine the grid size based on the orientation\n",
    "    if orientation == 'portrait':\n",
    "        grid_size = (short_edge_cells, long_edge_cells)\n",
    "    else:\n",
    "        grid_size = (long_edge_cells, short_edge_cells)\n",
    "\n",
    "    return grid_size\n",
    "\n",
    "# Prompt the user for the short_edge_cells value using tkinter\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "# Ask the user for the short edge size\n",
    "short_edge_cells = simpledialog.askinteger(\"Input\", \"Enter the number of cells for the short edge:\", minvalue=1)\n",
    "\n",
    "root.destroy()  # Close the tkinter root window\n",
    "\n",
    "if short_edge_cells is None:\n",
    "    raise ValueError(\"You must enter a valid number for the short edge size.\")\n",
    "\n",
    "# Set the mask file path\n",
    "mask_file = r\"C:\\Users\\TyHow\\Documents\\3. Work\\GIS Stuff\\ML_pilot_data\\MASK.geojson\"\n",
    "\n",
    "# Compute grid size using the mask file\n",
    "grid_size = compute_grid_size(mask_file, short_edge_cells=short_edge_cells)[::-1]\n",
    "print(f\"Calculated grid size: {grid_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT VECTOR FILES\n",
    "\n",
    "# Function to interactively select files\n",
    "def select_geojson_files():\n",
    "    # Create a Tkinter root window (hidden)\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "    # Open the file selection dialog\n",
    "    geojson_files = filedialog.askopenfilenames(\n",
    "        title=\"Select GeoJSON Files\",\n",
    "        filetypes=[(\"GeoJSON files\", \"*.geojson\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "    \n",
    "    root.destroy()  # Close the root window after selection\n",
    "    return list(geojson_files)  # Convert tuple to list and return\n",
    "\n",
    "# Use the function to select files\n",
    "geojson_files = select_geojson_files()\n",
    "\n",
    "# Print the selected files for verification\n",
    "print(f\"Selected GeoJSON files: {geojson_files}\")\n",
    "\n",
    "#SELECT VECTOR FILE LAYERS\n",
    "vector_features_to_process = []\n",
    "\n",
    "def select_columns(geojson_file):\n",
    "    \"\"\"Function to display column selection widgets for a given GeoJSON file.\"\"\"\n",
    "    # Read the GeoJSON file using GeoPandas\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    \n",
    "    # Get the list of columns\n",
    "    columns = gdf.columns.tolist()\n",
    "    \n",
    "    # Create a multiple selection widget for columns\n",
    "    selection = widgets.SelectMultiple(\n",
    "        options=columns,\n",
    "        description=f'Select columns for {os.path.basename(geojson_file)}:',\n",
    "        rows=10\n",
    "    )\n",
    "    \n",
    "    # Display the widget and button\n",
    "    display(selection)\n",
    "\n",
    "    # Define button click event\n",
    "    def on_button_click(b):\n",
    "        # For each selected column, create a tuple of (geojson_file, column_name)\n",
    "        selected_columns = [(geojson_file, col) for col in selection.value]\n",
    "        vector_features_to_process.extend(selected_columns)\n",
    "        print(f'Selected columns from {geojson_file}: {selected_columns}')\n",
    "    \n",
    "    # Create and display button\n",
    "    button = widgets.Button(description=\"Submit Selection\")\n",
    "    button.on_click(on_button_click)\n",
    "    display(button)\n",
    "\n",
    "# Iterate through each GeoJSON file and let the user select columns\n",
    "for file in geojson_files:\n",
    "    select_columns(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VECTOR PROCESSING FUNCTIONS\n",
    "\n",
    "# Function to process each cell in the grid\n",
    "def process_cell(idx, cell, gdf, sindex, feature_column, category_to_int, filename_prefix):\n",
    "    i, j = divmod(idx, grid_size[1])\n",
    "\n",
    "    # Use the spatial index to find potential intersecting polygons\n",
    "    possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "    if not possible_matches_index:\n",
    "        return i, j, np.nan\n",
    "\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    if possible_matches.empty:\n",
    "        return i, j, np.nan\n",
    "\n",
    "    intersections = possible_matches.geometry.intersection(cell)\n",
    "    valid_intersections = intersections[intersections.area > 0]\n",
    "\n",
    "    if valid_intersections.empty:\n",
    "        return i, j, np.nan\n",
    "\n",
    "    if len(valid_intersections) > 5:\n",
    "        areas_per_category = {}\n",
    "        for idx, intersection in enumerate(valid_intersections):\n",
    "            if not intersection.is_empty:\n",
    "                category = possible_matches.iloc[idx][feature_column]\n",
    "                category_key = f\"{filename_prefix}_{category}\"\n",
    "                if category_key not in areas_per_category:\n",
    "                    areas_per_category[category_key] = 0\n",
    "                areas_per_category[category_key] += intersection.area\n",
    "\n",
    "        if areas_per_category:\n",
    "            max_category = max(areas_per_category, key=areas_per_category.get)\n",
    "            return i, j, category_to_int[max_category]\n",
    "        else:\n",
    "            return i, j, np.nan\n",
    "    else:\n",
    "        largest_intersection_idx = valid_intersections.area.idxmax()\n",
    "        category = possible_matches.loc[largest_intersection_idx, feature_column]\n",
    "        return i, j, category_to_int[f\"{filename_prefix}_{category}\"]\n",
    "\n",
    "# Function to process each feature column\n",
    "def process_feature_column(geojson_file, feature_column, grid_size, target_crs, filename_prefix, x, y):\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    print(f\"Processing feature column: {feature_column} from file: {geojson_file}\")\n",
    "\n",
    "    gdf = gdf.to_crs(target_crs)\n",
    "    if gdf.empty:\n",
    "        print(f\"GeoDataFrame for {geojson_file} is empty after reprojecting. Skipping column: {feature_column}\")\n",
    "        return None\n",
    "\n",
    "    # Check if the geometry is a point\n",
    "    geom_type = gdf.geometry.geom_type.iloc[0]\n",
    "\n",
    "    if geom_type == \"Point\" or geom_type == \"MultiPoint\":\n",
    "        print(\"Detected point geometry, buffering...\")\n",
    "        gdf[\"geometry\"] = gdf.geometry.buffer(1000)  # Apply a buffer of 1000 meters to points\n",
    "\n",
    "    unique_categories = gdf[feature_column].unique()\n",
    "    print(f\"Unique categories in {feature_column}: {unique_categories}\")\n",
    "    category_to_int = {f\"{filename_prefix}_{cat}\": i for i, cat in enumerate(unique_categories)}\n",
    "\n",
    "    grid = np.full(grid_size, np.nan)\n",
    "    sindex = gdf.sindex\n",
    "\n",
    "    cells = [box(x[j], y[i], x[j + 1], y[i + 1])\n",
    "             for i in range(grid_size[0])\n",
    "             for j in range(grid_size[1])]\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_cell)(\n",
    "        idx, cell, gdf, sindex, feature_column, category_to_int, filename_prefix\n",
    "    ) for idx, cell in enumerate(cells))\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No results were generated for feature column: {feature_column} from file: {geojson_file}\")\n",
    "        return None\n",
    "\n",
    "    for i, j, value in results:\n",
    "        grid[i, j] = value\n",
    "\n",
    "    # Flip the grid vertically (along Y-axis)\n",
    "    grid_flipped = np.flipud(grid)\n",
    "\n",
    "    return (f\"{filename_prefix}_{feature_column}\", grid_flipped, category_to_int)\n",
    "\n",
    "# Batch processing function\n",
    "def geojson_to_numpy_grid_3d_batch(\n",
    "    grid_size: Tuple[int, int],  # Grid size for the output array\n",
    "    geojson_files: List[str],  # List of GeoJSON files\n",
    "    features_to_process: List[Tuple[str, str]],  # List of (file, feature) tuples to process\n",
    "    target_crs: str = \"EPSG:3857\"  # Web Mercator projection\n",
    ") -> Tuple[np.ndarray, Dict[str, np.ndarray], Dict[str, Dict[Any, int]], List[Dict[str, Any]]]:\n",
    "    all_feature_grids = {}\n",
    "    all_feature_mappings = {}\n",
    "    geospatial_info_list = []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Process each file and its corresponding features\n",
    "    for geojson_file in geojson_files:\n",
    "        # Get the filename without extension for prefixing\n",
    "        filename_prefix = os.path.splitext(os.path.basename(geojson_file))[0]\n",
    "\n",
    "        # Read the GeoJSON file to get the total bounds\n",
    "        gdf = gpd.read_file(geojson_file)\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "        minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "        x = np.linspace(minx, maxx, grid_size[1] + 1)\n",
    "        y = np.linspace(miny, maxy, grid_size[0] + 1)\n",
    "\n",
    "        # Extract relevant features for this file\n",
    "        file_features = [feature for file, feature in features_to_process if file == geojson_file]\n",
    "\n",
    "        # Store geospatial information for each file\n",
    "        geospatial_info = {\n",
    "            'transform': (minx, miny, maxx, maxy),\n",
    "            'crs': target_crs,\n",
    "            'file_name': filename_prefix\n",
    "        }\n",
    "        geospatial_info_list.append(geospatial_info)\n",
    "\n",
    "        # Use joblib to parallelize the processing of each feature column\n",
    "        results.extend(Parallel(n_jobs=-1)(delayed(process_feature_column)(\n",
    "            geojson_file, feature_column, grid_size, target_crs, filename_prefix, x, y\n",
    "        ) for feature_column in file_features))\n",
    "\n",
    "    for feature_name, grid, category_to_int in results:\n",
    "        all_feature_grids[feature_name] = grid\n",
    "        all_feature_mappings[feature_name] = category_to_int\n",
    "\n",
    "    grid_3d = np.stack(list(all_feature_grids.values()), axis=0)\n",
    "\n",
    "    return grid_3d, all_feature_grids, all_feature_mappings, geospatial_info_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT/PROCESS RASTERS\n",
    "\n",
    "#to defined grid with feature mappings\n",
    "\n",
    "# Get the bounding box of the mask file to use for target transform\n",
    "raster_gdf = gpd.read_file(mask_file)\n",
    "minx, miny, maxx, maxy = raster_gdf.total_bounds\n",
    "\n",
    "# Convert the GeoDataFrame to a projected CRS\n",
    "raster_gdf = raster_gdf.to_crs(\"EPSG:4326\")  # Project to a common projected CRS, e.g., EPSG:3857\n",
    "\n",
    "# Recalculate bounds in the projected CRS\n",
    "minx, miny, maxx, maxy = raster_gdf.total_bounds\n",
    "\n",
    "# Compute the target transform for the projected CRS\n",
    "raster_target_transform = from_bounds(minx, miny, maxx, maxy, grid_size[1], grid_size[0])\n",
    "raster_target_crs = \"EPSG:4326\"  # Set the target CRS to a projected coordinate system\n",
    "\n",
    "# Open a file selection dialog for the user to select multiple raster files\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "# Open the file selection dialog\n",
    "raster_files = askopenfilenames(\n",
    "    title=\"Select Raster Files\",\n",
    "    filetypes=[(\"GeoTIFF files\", \"*.tif\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "# Lists to store data and corresponding file names\n",
    "raster_data = []\n",
    "raster_names = []\n",
    "raster_feature_mappings = []  # List to store the mappings from filenames to their corresponding layers\n",
    "\n",
    "# Now, reproject and resample each raster to the common grid\n",
    "for layer_index, raster_file in enumerate(raster_files):\n",
    "    with rasterio.open(raster_file, 'r') as src:\n",
    "        print(f\"Processing file: {raster_file}\")\n",
    "        print(f\"Source CRS: {src.crs}\")\n",
    "        print(f\"Source Transform: {src.transform}\")\n",
    "        print(f\"Source Bounds: {src.bounds}\")\n",
    "\n",
    "        # Check if the source CRS matches the target CRS; reproject if needed\n",
    "        if src.crs != raster_target_crs:\n",
    "            src_crs = src.crs\n",
    "        else:\n",
    "            src_crs = raster_target_crs  # Keep the same CRS if already matching\n",
    "        \n",
    "        # Prepare the output array with NaN (representing no data)\n",
    "        raster_data_array = np.full(grid_size, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Handle NoData value\n",
    "        nodata_value = src.nodata\n",
    "        if nodata_value is None:\n",
    "            nodata_value = np.nan  # If NoData is not set, assume NaN\n",
    "\n",
    "        # Print debug information\n",
    "        print(f\"Reprojecting {raster_file} to target grid...\")\n",
    "        print(f\"Target CRS: {raster_target_crs}\")\n",
    "        print(f\"Target Transform: {raster_target_transform}\")\n",
    "        print(f\"Target Grid Size: {grid_size}\")\n",
    "\n",
    "        # Reproject the source data to the target grid\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=raster_data_array,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=raster_target_transform,\n",
    "            dst_crs=raster_target_crs,\n",
    "            resampling=Resampling.nearest,\n",
    "            src_nodata=nodata_value,\n",
    "            dst_nodata=np.nan  # Use NaN as the destination NoData\n",
    "        )\n",
    "\n",
    "        # Append the resampled data and names to lists\n",
    "        raster_data.append(raster_data_array)  # Append the resampled data array\n",
    "        file_name = os.path.basename(raster_file).replace('.tiff', '').replace('.tif', '')\n",
    "        raster_names.append(file_name)\n",
    "\n",
    "        # Append the filename to feature mappings with its corresponding layer index\n",
    "        raster_feature_mappings.append((file_name, layer_index))\n",
    "\n",
    "# Stack list into a 3D numpy array\n",
    "raster_data = np.stack(raster_data, axis=0)  # Stack the list of arrays into a 3D numpy array\n",
    "print(raster_data.shape, raster_names)\n",
    "print(\"Feature Mappings:\", raster_feature_mappings)  # Print the feature mappings\n",
    "\n",
    "# Check if all data layers contain NaN\n",
    "for i in range(raster_data.shape[0]):\n",
    "    print(f\"Layer {i} ({raster_names[i]}):\")\n",
    "    if np.all(np.isnan(raster_data[i])):\n",
    "        print(\"  All values are NaN.\")\n",
    "    else:\n",
    "        print(f\"  Min value: {np.nanmin(raster_data[i])}\")\n",
    "        print(f\"  Max value: {np.nanmax(raster_data[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROCESS VECTORS\n",
    "\n",
    "vector_data, vector_feature_grids, vector_feature_mappings, vector_geospatial_info_list = geojson_to_numpy_grid_3d_batch(grid_size, geojson_files, vector_features_to_process)\n",
    "\n",
    "# Print results\n",
    "print(\"Shape of the 3D grid array:\", vector_data.shape)\n",
    "print(\"Feature grids:\", vector_feature_grids.keys())\n",
    "print(\"Feature mappings:\", vector_feature_mappings)\n",
    "print(\"Geospatial information for each file:\", vector_geospatial_info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLE SLIDER PLOT\n",
    "\n",
    "data_to_plot = vector_data\n",
    "\n",
    "# Initialize the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Function to plot a specific layer using Matplotlib\n",
    "def plot_layer_bokeh(layer_index):\n",
    "    # Create the plot\n",
    "    fig = Figure(figsize=(3, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(data_to_plot[layer_index], cmap='viridis', interpolation='nearest', aspect='auto')\n",
    "    ax.set_title(f\"Layer {layer_index + 1}\")\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "# Create a Bokeh slider widget for selecting the layer\n",
    "layer_slider = pn.widgets.IntSlider(name='Layer Index', start=0, end=data_to_plot.shape[0] - 1, step=1, value=0)\n",
    "\n",
    "# Bind the plotting function to the slider value\n",
    "panel = pn.bind(plot_layer_bokeh, layer_index=layer_slider)\n",
    "\n",
    "# Display the Panel with the slider and plot\n",
    "pn.Column(layer_slider, panel).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE RASTER DATA\n",
    "\n",
    "# Hide the root window for file dialog\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "root.attributes(\"-topmost\", True)  # Bring the file dialog to the front\n",
    "\n",
    "# Prompt the user to select a folder to save the files\n",
    "output_directory = askdirectory(\n",
    "    initialdir=r\"C:\\Users\\TyHow\\Documents\\3. Work\\ML_test_area\\exports\",\n",
    "    title=\"Select a Folder to Save Output Files (BEWARE OVERWRITE!)\"\n",
    ")\n",
    "\n",
    "if output_directory:\n",
    "    # Construct file paths using the selected folder and default file names\n",
    "    output_6_rasters_file = os.path.join(output_directory, \"output_rasters.npy\")\n",
    "    output_6_rasters_layer_mappings_file = os.path.join(output_directory, \"output_rasters_layer_mappings.npy\")\n",
    "\n",
    "    # Save the files\n",
    "    np.save(output_6_rasters_file, raster_data)\n",
    "    np.save(output_6_rasters_layer_mappings_file, raster_feature_mappings)\n",
    "\n",
    "    print(f\"Files saved in: {output_directory}\")\n",
    "\n",
    "# Destroy the root window after file dialogs are closed\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE VECTOR DATA\n",
    "\n",
    "# Hide the root window for file dialog\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "root.attributes(\"-topmost\", True)  # Bring the file dialog to the front\n",
    "\n",
    "# Prompt the user to select a folder to save the files\n",
    "output_directory = askdirectory(\n",
    "    initialdir=r\"C:\\Users\\TyHow\\Documents\\3. Work\\ML_test_area\\exports\",\n",
    "    title=\"Select a Folder to Save Output Files (BEWARE OVERWRITE!)\"\n",
    ")\n",
    "\n",
    "if output_directory:\n",
    "    # Construct file paths using the selected folder and default file names\n",
    "    output_array_file = os.path.join(output_directory, \"output_vectors.npy\")\n",
    "    output_feature_grid_file = os.path.join(output_directory, \"output_vector_feature_grid.npy\")\n",
    "    output_feature_mappings_file = os.path.join(output_directory, \"output_vector_feature_mappings.npy\")\n",
    "    output_geospatial_info_file = os.path.join(output_directory, \"output_vector_geospatial_info.npy\")\n",
    "\n",
    "    # Save the files\n",
    "    np.save(output_array_file, vector_data)\n",
    "    np.save(output_feature_grid_file, vector_feature_grids)\n",
    "    np.save(output_feature_mappings_file, vector_feature_mappings)\n",
    "    np.save(output_geospatial_info_file, vector_geospatial_info_list)\n",
    "\n",
    "    print(f\"Files saved in: {output_directory}\")\n",
    "\n",
    "# Destroy the root window after file dialogs are closed\n",
    "root.destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NETCDF AS ARRAY\n",
    "\n",
    "# Function to prompt the user to select a .nc file\n",
    "def select_nc_file():\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "    # Open a file selection dialog\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select NetCDF File\",\n",
    "        filetypes=[(\"NetCDF files\", \"*.nc\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "\n",
    "    root.destroy()  # Close the root window after file selection\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# Function to convert a NetCDF file to a NumPy array\n",
    "def nc_to_numpy(file_path):\n",
    "    try:\n",
    "        # Load the NetCDF file using xarray\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Display available variables\n",
    "        print(\"Variables available in the NetCDF file:\")\n",
    "        for var in ds.data_vars:\n",
    "            print(var)\n",
    "        \n",
    "        # Select the variable to convert to NumPy array (adjust as needed)\n",
    "        var_name = input(\"Enter the variable name to convert to NumPy array: \")\n",
    "\n",
    "        if var_name in ds:\n",
    "            # Extract the variable and convert it to a NumPy array\n",
    "            data_array = ds[var_name].values\n",
    "            print(f\"Successfully converted {var_name} to a NumPy array with shape {data_array.shape}\")\n",
    "            return data_array\n",
    "        else:\n",
    "            print(f\"Variable '{var_name}' not found in the NetCDF file.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading NetCDF file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 1: Select the NetCDF file\n",
    "selected_file = select_nc_file()\n",
    "\n",
    "if selected_file:\n",
    "    print(f\"Selected file: {selected_file}\")\n",
    "    \n",
    "    # Step 2: Convert the selected NetCDF file to a NumPy array\n",
    "    nc_array = nc_to_numpy(selected_file)\n",
    "    \n",
    "    if nc_array is not None:\n",
    "        print(f\"Converted NumPy array shape: {nc_array.shape}\")\n",
    "else:\n",
    "    print(\"No file selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPLACE combined_data WITH IMPORTED .NC ARRAY\n",
    "combined_data = nc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINE ARRAYS\n",
    "\n",
    "# Ensure the arrays have the same x/y dimensions\n",
    "if vector_data.shape[1:] == raster_data.shape[1:]:\n",
    "    # Combine the arrays along the first axis (layers)\n",
    "    combined_data = np.concatenate((vector_data, raster_data), axis=0)\n",
    "\n",
    "    print(f\"Combined array shape: {combined_data.shape}\")\n",
    "else:\n",
    "    print(\"Error: The x/y dimensions of the arrays do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINE ARRAYS - WITH LAYER NAMES\n",
    "\n",
    "# Combine the arrays (vector and raster)\n",
    "if vector_data.shape[1:] == raster_data.shape[1:]:\n",
    "    combined_data = np.concatenate((vector_data, raster_data), axis=0)\n",
    "    print(f\"Combined array shape: {combined_data.shape}\")\n",
    "\n",
    "    # Initialize the layer name mapping list\n",
    "    combined_layer_names = []\n",
    "\n",
    "    # Add raster layer names (from file names)\n",
    "    for raster_name in raster_names:\n",
    "        combined_layer_names.append(raster_name)\n",
    "\n",
    "    # Add vector layer names (from feature names in vector_feature_grids)\n",
    "    for vector_feature_name in vector_feature_grids.keys():\n",
    "        combined_layer_names.append(vector_feature_name)\n",
    "\n",
    "    # Check the mapping to ensure it is correct\n",
    "    print(\"Layer Name Mapping List:\", combined_layer_names)\n",
    "\n",
    "    # Ensure the combined_data layers match the number of names\n",
    "    if len(layer_name_mapping) == combined_data.shape[0]:\n",
    "        print(f\"Layer name mapping successful. Total layers: {len(combined_layer_names)}\")\n",
    "    else:\n",
    "        print(f\"Warning: Mismatch in layers. {len(combined_layer_names)} names for {combined_data.shape[0]} layers.\")\n",
    "else:\n",
    "    print(\"Error: The x/y dimensions of the arrays do not match.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT COMBINED\n",
    "\n",
    "data_to_plot = combined_data\n",
    "\n",
    "# Initialize the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Function to plot a specific layer using Matplotlib\n",
    "def plot_layer_bokeh(layer_index):\n",
    "    # Create the plot\n",
    "    fig = Figure(figsize=(3, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(data_to_plot[layer_index], cmap='viridis', interpolation='nearest', aspect='auto')\n",
    "    ax.set_title(f\"Layer {layer_index + 1}\")\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "# Create a Bokeh slider widget for selecting the layer\n",
    "layer_slider = pn.widgets.IntSlider(name='Layer Index', start=0, end=data_to_plot.shape[0] - 1, step=1, value=0)\n",
    "\n",
    "# Bind the plotting function to the slider value\n",
    "panel = pn.bind(plot_layer_bokeh, layer_index=layer_slider)\n",
    "\n",
    "# Display the Panel with the slider and plot\n",
    "pn.Column(layer_slider, panel).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT COMBINED - with layer names\n",
    "\n",
    "data_to_plot = combined_data\n",
    "\n",
    "# Initialize the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Assuming combined_layer_names is a list that stores the names of each layer\n",
    "# combined_layer_names should be the list that maps to each layer of the combined_data array\n",
    "\n",
    "# Function to plot a specific layer using Matplotlib\n",
    "def plot_layer_bokeh(layer_index):\n",
    "    # Create the plot\n",
    "    fig = Figure(figsize=(3, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(data_to_plot[layer_index], cmap='viridis', interpolation='nearest', aspect='auto')\n",
    "    \n",
    "    # Use combined_layer_names for the title\n",
    "    ax.set_title(f\"Layer {layer_index + 1}: {combined_layer_names[layer_index]}\")\n",
    "    \n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "# Create a Bokeh slider widget for selecting the layer\n",
    "layer_slider = pn.widgets.IntSlider(name='Layer Index', start=0, end=data_to_plot.shape[0] - 1, step=1, value=0)\n",
    "\n",
    "# Bind the plotting function to the slider value\n",
    "panel = pn.bind(plot_layer_bokeh, layer_index=layer_slider)\n",
    "\n",
    "# Display the Panel with the slider and plot\n",
    "pn.Column(layer_slider, panel).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO XARRAY\n",
    "\n",
    "# Create dummy arrays for X, Y coordinates (you can replace these with your actual coordinates)\n",
    "x_coords = np.arange(combined_data.shape[2])  # X-coordinates (along the third axis)\n",
    "y_coords = np.arange(combined_data.shape[1])  # Y-coordinates (along the second axis)\n",
    "layer_names = combined_layer_names  # Layer names\n",
    "\n",
    "# Create an xarray DataArray from the combined NumPy array\n",
    "data_xr = xr.DataArray(\n",
    "    combined_data, \n",
    "    dims=[\"layer\", \"y\", \"x\"], \n",
    "    coords={\"layer\": layer_names, \"y\": y_coords, \"x\": x_coords},\n",
    "    name=\"combined_layers\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT XARRAY TO NETCDF\n",
    "\n",
    "# Hide the root window for the file dialog\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "root.attributes(\"-topmost\", True)  # Bring the file dialog to the front\n",
    "\n",
    "# Prompt the user to select a location to save the NetCDF file\n",
    "output_file = asksaveasfilename(\n",
    "    initialfile=\"THE_CUBE.nc\",  # Default file name\n",
    "    defaultextension=\".nc\",  # Default extension\n",
    "    filetypes=[(\"NetCDF files\", \"*.nc\"), (\"All files\", \"*.*\")],\n",
    "    title=\"Save NetCDF file\"\n",
    ")\n",
    "\n",
    "# If the user provides a location, save the NetCDF file\n",
    "if output_file:\n",
    "    data_xr.to_netcdf(output_file)\n",
    "    print(f\"Data successfully exported to {output_file}\")\n",
    "\n",
    "# Destroy the root window after file dialog is closed\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE CHECKERBOARD FUNCTION\n",
    "\n",
    "def make_checkerboard(board_size: tuple[int, int], square_size: tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a checkerboard pattern.\n",
    "\n",
    "    props to stackoverflow user Blubberguy22, posted March 17, 2020 at 19:00\n",
    "    https://stackoverflow.com/questions/2169478/how-to-make-a-checkerboard-in-numpy\n",
    "\n",
    "    Parameters:\n",
    "        board_size (tuple[int, int]): Size of the board in rows and columns.\n",
    "        square_size (tuple[int, int]): Size of each square in rows and columns.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Checkerboard pattern as a NumPy array.\n",
    "    \"\"\"\n",
    "    rows, cols = board_size\n",
    "    sq_rows, sq_cols = square_size\n",
    "\n",
    "    # Calculate the checkerboard pattern efficiently\n",
    "    row_indices = np.arange(rows) // sq_rows\n",
    "    col_indices = np.arange(cols) // sq_cols\n",
    "    checkerboard = (row_indices[:, np.newaxis] + col_indices) % 2\n",
    "\n",
    "    return checkerboard.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make checkerboard\n",
    "checker = make_checkerboard(combined_data[0].shape, (100,100))\n",
    "#checker[nodata_mask] = np.nan\n",
    "\n",
    "#plot checkerboard\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(checker)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data into checkers\n",
    "X_check0 = X_pix[checker.flatten()==0]\n",
    "y_check0 = y_pix[checker.flatten()==0]\n",
    "\n",
    "X_check1 = X_pix[checker.flatten()==1]\n",
    "y_check1 = y_pix[checker.flatten()==1]\n",
    "\n",
    "# remove nans\n",
    "X_check0 = X_check0[~np.isnan(y_check0)]\n",
    "y_check0 = y_check0[~np.isnan(y_check0)]\n",
    "\n",
    "X_check1 = X_check1[~np.isnan(y_check1)]\n",
    "y_check1 = y_check1[~np.isnan(y_check1)]\n",
    "\n",
    "# print some details\n",
    "print ('Checker 0: X data array shape is {}, y labels array shape is {}'.format(X_check0.shape, y_check0.shape))\n",
    "print ('Checker 1: X data array shape is {}, y labels array shape is {}'.format(X_check1.shape, y_check1.shape))\n",
    "\n",
    "# run undersampling\n",
    "X_check0, y_check0 = rus.fit_resample(X_check0, y_check0)\n",
    "X_check1, y_check1 = rus.fit_resample(X_check1, y_check1)\n",
    "\n",
    "# print some details\n",
    "print ('Checker 0: X data array shape is {}, y labels array shape is {}'.format(X_check0.shape, y_check0.shape))\n",
    "print ('Checker 1: X data array shape is {}, y labels array shape is {}'.format(X_check1.shape, y_check1.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
