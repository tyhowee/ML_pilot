{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"c908ccf6-0005-4ab2-81b1-d06a064e4019\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"3fb10846-04d8-4c4e-9088-abc250774364\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"fed987bdda074ec78f6a98a045712c78\",\"client_comm_id\":\"04f25c8ed6404f16bf8ab585214465d2\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"3fb10846-04d8-4c4e-9088-abc250774364\",\"roots\":{\"p1002\":\"c908ccf6-0005-4ab2-81b1-d06a064e4019\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IMPORTS\n",
    "\n",
    "from typing import Tuple, Dict, Any, List\n",
    "import os\n",
    "from tkinter import Tk, filedialog, simpledialog, Toplevel, Button, Checkbutton, IntVar, Label, Frame\n",
    "from tkinter.filedialog import askopenfilenames, askdirectory, asksaveasfilename\n",
    "\n",
    "import cupy as cp\n",
    "import geopandas as gpd\n",
    "import hvplot.xarray\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.widgets import Slider\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.features import rasterize\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from scipy import stats\n",
    "from scipy.ndimage import generic_filter\n",
    "from scipy.stats import mode\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import box\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import easygui\n",
    "\n",
    "from CheckmateSample import make_checkerboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated grid size: (1033, 800)\n"
     ]
    }
   ],
   "source": [
    "#CALCULATE GRID SIZE (from mask short edge)\n",
    "\n",
    "# Function to compute grid size based on the mask file\n",
    "def compute_grid_size(geojson_file: str, short_edge_cells: int = 20) -> Tuple[int, int]:\n",
    "    # Read the GeoJSON file using GeoPandas\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    \n",
    "    # Get the bounding box of the masking region\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    \n",
    "    # Calculate width and height of the bounding box\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    # Determine which is the short and long edge\n",
    "    if width < height:\n",
    "        short_edge = width\n",
    "        long_edge = height\n",
    "        orientation = 'portrait'\n",
    "    else:\n",
    "        short_edge = height\n",
    "        long_edge = width\n",
    "        orientation = 'landscape'\n",
    "\n",
    "    # Compute the aspect ratio\n",
    "    aspect_ratio = long_edge / short_edge\n",
    "\n",
    "    # Compute the number of cells for the long edge\n",
    "    long_edge_cells = int(short_edge_cells * aspect_ratio)\n",
    "\n",
    "    # Determine the grid size based on the orientation\n",
    "    if orientation == 'portrait':\n",
    "        grid_size = (short_edge_cells, long_edge_cells)\n",
    "    else:\n",
    "        grid_size = (long_edge_cells, short_edge_cells)\n",
    "\n",
    "    return grid_size\n",
    "\n",
    "# Prompt the user for the short_edge_cells value using tkinter\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "# Ask the user for the short edge size\n",
    "short_edge_cells = simpledialog.askinteger(\"Input\", \"Enter the number of cells for the short edge:\", minvalue=1)\n",
    "\n",
    "root.destroy()  # Close the tkinter root window\n",
    "\n",
    "if short_edge_cells is None:\n",
    "    raise ValueError(\"You must enter a valid number for the short edge size.\")\n",
    "\n",
    "# Set the mask file path\n",
    "mask_file = r\"C:\\Users\\TyHow\\Documents\\3. Work\\GIS Stuff\\ML_pilot_data\\MASK.geojson\"\n",
    "\n",
    "# Compute grid size using the mask file\n",
    "grid_size = compute_grid_size(mask_file, short_edge_cells=short_edge_cells)[::-1]\n",
    "print(f\"Calculated grid size: {grid_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected GeoJSON files: ['C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson', 'C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/M162-Deposits_CLIPPED.geojson']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6f84b26f774239aa66a2e15ec805a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select columns for geology_clipped.geojson:', options=('fid', 'CD_CORRELA', 'ESCAL…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aff188de73249798ce98178632c6d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit Selection', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c0151661184b3a84d159cbbff4870b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select columns for M162-Deposits_CLIPPED.geojson:', options=('fid', 'deposit_refer…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034dffb0dc0542f5b1350877025c74fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit Selection', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns from C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson: [('C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson', 'fid'), ('C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson', 'SUBTIPO_DE'), ('C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson', 'CODIGO'), ('C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson', 'DEFINICION'), ('C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson', 'UNIDAD_GEN')]\n",
      "Selected columns from C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/M162-Deposits_CLIPPED.geojson: [('C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/M162-Deposits_CLIPPED.geojson', 'fid')]\n"
     ]
    }
   ],
   "source": [
    "#SELECT VECTOR FILES\n",
    "\n",
    "# Function to interactively select files\n",
    "def select_geojson_files():\n",
    "    # Create a Tkinter root window (hidden)\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "    # Open the file selection dialog\n",
    "    geojson_files = filedialog.askopenfilenames(\n",
    "        title=\"Select GeoJSON Files\",\n",
    "        filetypes=[(\"GeoJSON files\", \"*.geojson\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "    \n",
    "    root.destroy()  # Close the root window after selection\n",
    "    return list(geojson_files)  # Convert tuple to list and return\n",
    "\n",
    "# Use the function to select files\n",
    "geojson_files = select_geojson_files()\n",
    "\n",
    "# Print the selected files for verification\n",
    "print(f\"Selected GeoJSON files: {geojson_files}\")\n",
    "\n",
    "#SELECT VECTOR FILE LAYERS\n",
    "vector_features_to_process = []\n",
    "\n",
    "def select_columns(geojson_file):\n",
    "    \"\"\"Function to display column selection widgets for a given GeoJSON file.\"\"\"\n",
    "    # Read the GeoJSON file using GeoPandas\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    \n",
    "    # Get the list of columns\n",
    "    columns = gdf.columns.tolist()\n",
    "    \n",
    "    # Create a multiple selection widget for columns\n",
    "    selection = widgets.SelectMultiple(\n",
    "        options=columns,\n",
    "        description=f'Select columns for {os.path.basename(geojson_file)}:',\n",
    "        rows=10\n",
    "    )\n",
    "    \n",
    "    # Display the widget and button\n",
    "    display(selection)\n",
    "\n",
    "    # Define button click event\n",
    "    def on_button_click(b):\n",
    "        # For each selected column, create a tuple of (geojson_file, column_name)\n",
    "        selected_columns = [(geojson_file, col) for col in selection.value]\n",
    "        vector_features_to_process.extend(selected_columns)\n",
    "        print(f'Selected columns from {geojson_file}: {selected_columns}')\n",
    "    \n",
    "    # Create and display button\n",
    "    button = widgets.Button(description=\"Submit Selection\")\n",
    "    button.on_click(on_button_click)\n",
    "    display(button)\n",
    "\n",
    "# Iterate through each GeoJSON file and let the user select columns\n",
    "for file in geojson_files:\n",
    "    select_columns(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VECTOR PROCESSING FUNCTIONS\n",
    "\n",
    "def process_cell(idx, cell, gdf, sindex, feature_column, category_to_int, point_geometry=False):\n",
    "    i, j = divmod(idx, grid_size[1])\n",
    "\n",
    "    # Use the spatial index to find potential intersecting polygons or buffered points\n",
    "    possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "    if not possible_matches_index:\n",
    "        return i, j, 0 if point_geometry else np.nan  # Set 0 if no point is found, NaN for polygons\n",
    "\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    if possible_matches.empty:\n",
    "        return i, j, 0 if point_geometry else np.nan  # Set 0 if no point is found\n",
    "\n",
    "    if point_geometry:\n",
    "        # For points, return 1 (point of interest) if there's a match\n",
    "        return i, j, 1\n",
    "    \n",
    "    # For polygons, find intersections\n",
    "    intersections = possible_matches.geometry.intersection(cell)\n",
    "    valid_intersections = intersections[intersections.area > 0]\n",
    "\n",
    "    if valid_intersections.empty:\n",
    "        return i, j, np.nan\n",
    "\n",
    "    if len(valid_intersections) > 5:\n",
    "        areas_per_category = {}\n",
    "        for idx, intersection in enumerate(valid_intersections):\n",
    "            if not intersection.is_empty:\n",
    "                category = possible_matches.iloc[idx][feature_column]\n",
    "                # Use the raw category (no file name prefix)\n",
    "                if category not in areas_per_category:\n",
    "                    areas_per_category[category] = 0\n",
    "                areas_per_category[category] += intersection.area\n",
    "\n",
    "        if areas_per_category:\n",
    "            max_category = max(areas_per_category, key=areas_per_category.get)\n",
    "            return i, j, category_to_int[max_category]\n",
    "        else:\n",
    "            return i, j, np.nan\n",
    "    else:\n",
    "        largest_intersection_idx = valid_intersections.area.idxmax()\n",
    "        category = possible_matches.loc[largest_intersection_idx, feature_column]\n",
    "        # Use raw category here as well\n",
    "        return i, j, category_to_int[category]\n",
    "\n",
    "\n",
    "# Function to process each feature column\n",
    "def process_feature_column(geojson_file, feature_column, grid_size, target_crs, x, y):\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    print(f\"Processing feature column: {feature_column} from file: {geojson_file}\")\n",
    "\n",
    "    gdf = gdf.to_crs(target_crs)\n",
    "    if gdf.empty:\n",
    "        print(f\"GeoDataFrame for {geojson_file} is empty after reprojecting. Skipping column: {feature_column}\")\n",
    "        return None\n",
    "\n",
    "    # Check if the geometry is a point\n",
    "    geom_type = gdf.geometry.geom_type.iloc[0]\n",
    "\n",
    "    # For point geometries, buffer and treat them as points of interest (binary values)\n",
    "    point_geometry = False\n",
    "    if geom_type == \"Point\" or geom_type == \"MultiPoint\":\n",
    "        print(\"Detected point geometry, buffering and marking points of interest...\")\n",
    "        gdf[\"geometry\"] = gdf.geometry.buffer(1000)  # Buffer of 1000 meters\n",
    "        point_geometry = True\n",
    "\n",
    "    # Remove filename from category_to_int key and only use field names for values\n",
    "    unique_categories = gdf[feature_column].unique() if not point_geometry else [\"Point of Interest\"]\n",
    "    \n",
    "    # Adjust here to map point of interest to 1 instead of 0\n",
    "    category_to_int = {cat: 1 if cat == \"Point of Interest\" else i for i, cat in enumerate(unique_categories)}\n",
    "\n",
    "    grid = np.full(grid_size, np.nan if not point_geometry else 0)  # Set to 0 for binary if point data\n",
    "    sindex = gdf.sindex\n",
    "\n",
    "    cells = [box(x[j], y[i], x[j + 1], y[i + 1])\n",
    "             for i in range(grid_size[0])\n",
    "             for j in range(grid_size[1])]\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_cell)(\n",
    "        idx, cell, gdf, sindex, feature_column, category_to_int, point_geometry\n",
    "    ) for idx, cell in enumerate(cells))\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No results were generated for feature column: {feature_column} from file: {geojson_file}\")\n",
    "        return None\n",
    "\n",
    "    for i, j, value in results:\n",
    "        grid[i, j] = value\n",
    "\n",
    "    # Flip the grid vertically (along Y-axis)\n",
    "    grid_flipped = np.flipud(grid)\n",
    "\n",
    "    # Strip '.geojson' from the file name to clean up field names\n",
    "    filename_cleaned = os.path.basename(geojson_file).replace('.geojson', '')\n",
    "    return (f\"{filename_cleaned}_{feature_column}\", grid_flipped, category_to_int)\n",
    "\n",
    "\n",
    "# Batch processing function\n",
    "def geojson_to_numpy_grid_3d_batch(\n",
    "    grid_size: Tuple[int, int],  # Grid size for the output array\n",
    "    geojson_files: List[str],  # List of GeoJSON files\n",
    "    features_to_process: List[Tuple[str, str]],  # List of (file, feature) tuples to process\n",
    "    target_crs: str = \"EPSG:3857\"  # Web Mercator projection\n",
    ") -> Tuple[np.ndarray, Dict[str, np.ndarray], Dict[str, Dict[Any, int]], List[Dict[str, Any]]]:\n",
    "    all_feature_grids = {}\n",
    "    all_feature_mappings = {}  # Initialize all_feature_mappings to track the category mappings\n",
    "    geospatial_info_list = []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Process each file and its corresponding features\n",
    "    for geojson_file in geojson_files:\n",
    "        # Get the filename without extension for prefixing the field names\n",
    "        filename_prefix = os.path.basename(geojson_file).replace('.geojson', '').replace('.json', '')\n",
    "\n",
    "\n",
    "        # Read the GeoJSON file to get the total bounds\n",
    "        gdf = gpd.read_file(geojson_file)\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "        minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "        x = np.linspace(minx, maxx, grid_size[1] + 1)\n",
    "        y = np.linspace(miny, maxy, grid_size[0] + 1)\n",
    "\n",
    "        # Extract relevant features for this file\n",
    "        file_features = [feature for file, feature in features_to_process if file == geojson_file]\n",
    "\n",
    "        # Store geospatial information for each file\n",
    "        geospatial_info = {\n",
    "            'transform': (minx, miny, maxx, maxy),\n",
    "            'crs': target_crs,\n",
    "            'file_name': filename_prefix\n",
    "        }\n",
    "        geospatial_info_list.append(geospatial_info)\n",
    "\n",
    "        # Use joblib to parallelize the processing of each feature column\n",
    "        results.extend(Parallel(n_jobs=-1)(delayed(process_feature_column)(\n",
    "            geojson_file, feature_column, grid_size, target_crs, x, y\n",
    "        ) for feature_column in file_features))\n",
    "\n",
    "    for feature_name, grid, category_to_int in results:\n",
    "        all_feature_grids[feature_name] = grid\n",
    "        all_feature_mappings[feature_name] = category_to_int  # Store category mappings for each feature\n",
    "\n",
    "    grid_3d = np.stack(list(all_feature_grids.values()), axis=0)\n",
    "\n",
    "    return grid_3d, all_feature_grids, all_feature_mappings, geospatial_info_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED.tiff.tif\n",
      "Source CRS: EPSG:4326\n",
      "Source Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Source Bounds: BoundingBox(left=-70.84314607212116, bottom=-30.99739084675005, right=-70.50676780294046, top=-30.61902651198721)\n",
      "Reprojecting C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED.tiff.tif to target grid...\n",
      "Target CRS: EPSG:4326\n",
      "Target Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Target Grid Size: (1033, 800)\n",
      "Processing file: C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/argz_indices_1340_test_larger_area_CLIPPED.tiff.tif\n",
      "Source CRS: EPSG:4326\n",
      "Source Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Source Bounds: BoundingBox(left=-70.84314607212116, bottom=-30.99739084675005, right=-70.50676780294046, top=-30.61902651198721)\n",
      "Reprojecting C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/argz_indices_1340_test_larger_area_CLIPPED.tiff.tif to target grid...\n",
      "Target CRS: EPSG:4326\n",
      "Target Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Target Grid Size: (1033, 800)\n",
      "Processing file: C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/bsi_indices_1340_test_larger_area_CLIPPED.tiff.tif\n",
      "Source CRS: EPSG:4326\n",
      "Source Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Source Bounds: BoundingBox(left=-70.84314607212116, bottom=-30.99739084675005, right=-70.50676780294046, top=-30.61902651198721)\n",
      "Reprojecting C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/bsi_indices_1340_test_larger_area_CLIPPED.tiff.tif to target grid...\n",
      "Target CRS: EPSG:4326\n",
      "Target Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Target Grid Size: (1033, 800)\n",
      "Processing file: C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/clay_minerals_indices_1340_test_larger_area_CLIPPED.tiff.tif\n",
      "Source CRS: EPSG:4326\n",
      "Source Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Source Bounds: BoundingBox(left=-70.84322609027531, bottom=-30.997316890832987, right=-70.50704192771636, top=-30.6193808242143)\n",
      "Reprojecting C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/clay_minerals_indices_1340_test_larger_area_CLIPPED.tiff.tif to target grid...\n",
      "Target CRS: EPSG:4326\n",
      "Target Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Target Grid Size: (1033, 800)\n",
      "Processing file: C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/goethite_s2_copper_sam_1340_test_larger_area_CLIPPED.tiff.tif\n",
      "Source CRS: EPSG:4326\n",
      "Source Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Source Bounds: BoundingBox(left=-70.84314607212116, bottom=-30.99739084675005, right=-70.50676780294046, top=-30.61902651198721)\n",
      "Reprojecting C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/goethite_s2_copper_sam_1340_test_larger_area_CLIPPED.tiff.tif to target grid...\n",
      "Target CRS: EPSG:4326\n",
      "Target Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Target Grid Size: (1033, 800)\n",
      "Processing file: C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/illite_indices_1340_test_larger_area_CLIPPED.tiff.tif\n",
      "Source CRS: EPSG:4326\n",
      "Source Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Source Bounds: BoundingBox(left=-70.84322609027531, bottom=-30.997316890832987, right=-70.50704192771636, top=-30.6193808242143)\n",
      "Reprojecting C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/rs_data/clipped/illite_indices_1340_test_larger_area_CLIPPED.tiff.tif to target grid...\n",
      "Target CRS: EPSG:4326\n",
      "Target Transform: | 0.00, 0.00,-70.84|\n",
      "| 0.00,-0.00,-30.62|\n",
      "| 0.00, 0.00, 1.00|\n",
      "Target Grid Size: (1033, 800)\n",
      "(6, 1033, 800) ['alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED', 'argz_indices_1340_test_larger_area_CLIPPED', 'bsi_indices_1340_test_larger_area_CLIPPED', 'clay_minerals_indices_1340_test_larger_area_CLIPPED', 'goethite_s2_copper_sam_1340_test_larger_area_CLIPPED', 'illite_indices_1340_test_larger_area_CLIPPED']\n",
      "Feature Mappings: [('alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED', 0), ('argz_indices_1340_test_larger_area_CLIPPED', 1), ('bsi_indices_1340_test_larger_area_CLIPPED', 2), ('clay_minerals_indices_1340_test_larger_area_CLIPPED', 3), ('goethite_s2_copper_sam_1340_test_larger_area_CLIPPED', 4), ('illite_indices_1340_test_larger_area_CLIPPED', 5)]\n",
      "Layer 0 (alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED):\n",
      "  Min value: 0.6034116148948669\n",
      "  Max value: 0.9945110082626343\n",
      "Layer 1 (argz_indices_1340_test_larger_area_CLIPPED):\n",
      "  Min value: 0.0\n",
      "  Max value: 3.0\n",
      "Layer 2 (bsi_indices_1340_test_larger_area_CLIPPED):\n",
      "  Min value: 0.0\n",
      "  Max value: 0.6956691145896912\n",
      "Layer 3 (clay_minerals_indices_1340_test_larger_area_CLIPPED):\n",
      "  Min value: 0.0\n",
      "  Max value: 2.251274585723877\n",
      "Layer 4 (goethite_s2_copper_sam_1340_test_larger_area_CLIPPED):\n",
      "  Min value: 0.4606357216835022\n",
      "  Max value: 0.9837725758552551\n",
      "Layer 5 (illite_indices_1340_test_larger_area_CLIPPED):\n",
      "  Min value: 0.0\n",
      "  Max value: 3.0\n"
     ]
    }
   ],
   "source": [
    "#SELECT/PROCESS RASTERS\n",
    "\n",
    "#to defined grid with feature mappings\n",
    "\n",
    "# Get the bounding box of the mask file to use for target transform\n",
    "raster_gdf = gpd.read_file(mask_file)\n",
    "minx, miny, maxx, maxy = raster_gdf.total_bounds\n",
    "\n",
    "# Convert the GeoDataFrame to a projected CRS\n",
    "raster_gdf = raster_gdf.to_crs(\"EPSG:4326\")  # Project to a common projected CRS, e.g., EPSG:3857\n",
    "\n",
    "# Recalculate bounds in the projected CRS\n",
    "minx, miny, maxx, maxy = raster_gdf.total_bounds\n",
    "\n",
    "# Compute the target transform for the projected CRS\n",
    "raster_target_transform = from_bounds(minx, miny, maxx, maxy, grid_size[1], grid_size[0])\n",
    "raster_target_crs = \"EPSG:4326\"  # Set the target CRS to a projected coordinate system\n",
    "\n",
    "# Open a file selection dialog for the user to select multiple raster files\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "# Open the file selection dialog\n",
    "raster_files = askopenfilenames(\n",
    "    title=\"Select Raster Files\",\n",
    "    filetypes=[(\"GeoTIFF files\", \"*.tif\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "# Lists to store data and corresponding file names\n",
    "raster_data = []\n",
    "raster_names = []\n",
    "raster_feature_mappings = []  # List to store the mappings from filenames to their corresponding layers\n",
    "\n",
    "# Now, reproject and resample each raster to the common grid\n",
    "for layer_index, raster_file in enumerate(raster_files):\n",
    "    with rasterio.open(raster_file, 'r') as src:\n",
    "        print(f\"Processing file: {raster_file}\")\n",
    "        print(f\"Source CRS: {src.crs}\")\n",
    "        print(f\"Source Transform: {src.transform}\")\n",
    "        print(f\"Source Bounds: {src.bounds}\")\n",
    "\n",
    "        # Check if the source CRS matches the target CRS; reproject if needed\n",
    "        if src.crs != raster_target_crs:\n",
    "            src_crs = src.crs\n",
    "        else:\n",
    "            src_crs = raster_target_crs  # Keep the same CRS if already matching\n",
    "        \n",
    "        # Prepare the output array with NaN (representing no data)\n",
    "        raster_data_array = np.full(grid_size, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Handle NoData value\n",
    "        nodata_value = src.nodata\n",
    "        if nodata_value is None:\n",
    "            nodata_value = np.nan  # If NoData is not set, assume NaN\n",
    "\n",
    "        # Print debug information\n",
    "        print(f\"Reprojecting {raster_file} to target grid...\")\n",
    "        print(f\"Target CRS: {raster_target_crs}\")\n",
    "        print(f\"Target Transform: {raster_target_transform}\")\n",
    "        print(f\"Target Grid Size: {grid_size}\")\n",
    "\n",
    "        # Reproject the source data to the target grid\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=raster_data_array,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=raster_target_transform,\n",
    "            dst_crs=raster_target_crs,\n",
    "            resampling=Resampling.nearest,\n",
    "            src_nodata=nodata_value,\n",
    "            dst_nodata=np.nan  # Use NaN as the destination NoData\n",
    "        )\n",
    "\n",
    "        # Append the resampled data and names to lists\n",
    "        raster_data.append(raster_data_array)  # Append the resampled data array\n",
    "        file_name = os.path.basename(raster_file).replace('.tiff', '').replace('.tif', '')\n",
    "        raster_names.append(file_name)\n",
    "\n",
    "        # Append the filename to feature mappings with its corresponding layer index\n",
    "        raster_feature_mappings.append((file_name, layer_index))\n",
    "\n",
    "# Stack list into a 3D numpy array\n",
    "raster_data = np.stack(raster_data, axis=0)  # Stack the list of arrays into a 3D numpy array\n",
    "print(raster_data.shape, raster_names)\n",
    "print(\"Feature Mappings:\", raster_feature_mappings)  # Print the feature mappings\n",
    "\n",
    "# Check if all data layers contain NaN\n",
    "for i in range(raster_data.shape[0]):\n",
    "    print(f\"Layer {i} ({raster_names[i]}):\")\n",
    "    if np.all(np.isnan(raster_data[i])):\n",
    "        print(\"  All values are NaN.\")\n",
    "    else:\n",
    "        print(f\"  Min value: {np.nanmin(raster_data[i])}\")\n",
    "        print(f\"  Max value: {np.nanmax(raster_data[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the 3D grid array: (6, 1033, 800)\n",
      "Feature grids: dict_keys(['geology_clipped_fid', 'geology_clipped_SUBTIPO_DE', 'geology_clipped_CODIGO', 'geology_clipped_DEFINICION', 'geology_clipped_UNIDAD_GEN', 'M162-Deposits_CLIPPED_fid'])\n",
      "Feature mappings: {'geology_clipped_fid': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177}, 'geology_clipped_SUBTIPO_DE': {'AMBIENTE SEDIMENTARIO': 0, 'AMBIENTE PLUTONICO': 1, 'AMBIENTE SUBVOLCANICO HIPABISAL': 2, 'AMBIENTE VOLCANICO': 3, 'AMBIENTE VOLCANICO SEDIMENTARIO': 4}, 'geology_clipped_CODIGO': {'Kp': 0, 'Hf': 1, 'Krt': 2, 'PlHa': 3, 'Jm': 4, 'PlHc': 5, 'Plf': 6, 'PaEdc': 7, 'KPadp(gd)': 8, 'PaEdh(gd)': 9, 'PaEdc(gd)': 10, 'KPadp(g)': 11, 'Pg': 12, 'Cg': 13, 'PaEgdr': 14, 'PaEgdg': 15, 'Edm': 16, 'PaEgdg(d)': 17, 'Eih(a)': 18, 'Ksih(a)': 19, 'Kv(b)': 20, 'Kle': 21, 'Ja': 22, 'Kv(a)': 23, 'Jtc(b)': 24, 'Jtc(a)': 25, 'Jtc(c)': 26}, 'geology_clipped_DEFINICION': {'Secuencia sedimentaria continental conformada por conglomerados, areniscas, calizas y limolitas.': 0, 'Depósitos no consolidados, estratiformes a lenticulares, constituidos por bolones, gravas y arenas.': 1, 'Secuencia marina de calizas con calcarenitas, calcilutitas, areniscas arcósicas y volcanoarenitas.': 2, 'Depósitos de gravas y bloques no consolidados, los que forman conos en la salida de quebradas.': 3, 'Secuencia sedimentaria compuesta de conglomerados, brechas tobáceas y areniscas.': 4, 'Depósitos de gravas no consolidadas, las que forman conos o abanicos en las cabeceras de quebradas.': 5, 'Depósitos de gravas muy gruesas con matriz de arena, con intercalaciones de gravas finas arenosas.': 6, 'Unidad intrusiva constituida por cuerpos de diorita de anfíbola-piroxeno, y pórfidos de granodiori': 7, 'Facie de la Diorita Pichasca compuesta por granodioritas de anfíbola-biotita.': 8, 'Facie de la Diorita Huevilos compuesta por granodioritas de anfíbola y biotita.': 9, 'Facie de la Diorita Campanario, compuesta por pórfidos granodioríticos y dacíticos.': 10, 'Facie de la Diorita Pichasca compuesta por granitos de biotita de grano medio.': 11, 'Cuerpos intrusivos tabulares de color gris, formados principalmente por tonalitas y granodioritas.': 12, 'Cuerpos intrusivos de color gris a rosado, formados principalmente por granodioritas y monzogranitos': 13, 'Unidad intrusiva compuesta por granodioritas y facies subordinadas de granitos de grano medio.': 14, 'Unidad intrusiva compuesta por granodioritas de grano medio de biotita-anfíbola y granito de biotit': 15, 'Compuesto por dioritas, dioritas cuarcíferas y tonalitas de grano fino, de anfíbola-biotita.': 16, 'Facie de la Granodiorita Guatulame compuesta por microdioritas porfídicas de anfíbola.': 17, 'Pórfidos andesíticos-basálticos de clinopiroxeno, olivino-clinopiroxeno y piroxeno-anfíbola.': 18, 'Facie de los Intrusivos hipabisales andesíticos conformado por pórfidos andesíticos y dioriticos.': 19, 'Facie de la Formación Viñita compuesta por tobas, andesitas y andesitas-basálticas.': 20, 'Secuencia volcanosedimentaria continental formada por coladas, tobas y brechas piroclásticas.': 21, 'Secuencia de coladas de andesitas, areniscas y niveles restringidos de tobas de cristales y líticos': 22, 'Facie de la Formación Viñita compuesta por andesitas, tobas, areniscas y brechas piroclásticas.': 23, 'Facie de la Formación Tres Cruces conformada por conglomerados gruesos, basaltos y andesitas.': 24, 'Facie de la Formación Tres Cruces conformada por conglomerados, areniscas y calcilutitas.': 25, 'Facie de la Formación Tres Cruces conformada por conglomerados, areniscas y coladas andesíticas.': 26}, 'geology_clipped_UNIDAD_GEN': {'Kp': 0, 'Hf': 1, 'Krt': 2, 'PlHa': 3, 'Jm': 4, 'PlHc': 5, 'Plf': 6, 'PaEdc': 7, 'KPadp(gd)': 8, 'PaEdh(gd)': 9, 'PaEdc(gd)': 10, 'KPadp(g)': 11, 'Pg': 12, 'Cg': 13, 'PaEgdr': 14, 'PaEgdg': 15, 'Edm': 16, 'PaEgdg(d)': 17, 'Eih(a)': 18, 'Ksih(a)': 19, 'Kv(b)': 20, 'Kle': 21, 'Ja': 22, 'Kv(a)': 23, 'Jtc(b)': 24, 'Jtc(a)': 25, 'Jtc(c)': 26}, 'M162-Deposits_CLIPPED_fid': {'Point of Interest': 1}}\n",
      "Geospatial information for each file: [{'transform': (-7886233.879223923, -3632432.80288566, -7848762.490354943, -3583369.988284047), 'crs': 'EPSG:3857', 'file_name': 'geology_clipped'}, {'transform': (-7884457.948354366, -3632126.4389277147, -7853178.630219428, -3587392.3670124407), 'crs': 'EPSG:3857', 'file_name': 'M162-Deposits_CLIPPED'}]\n"
     ]
    }
   ],
   "source": [
    "#PROCESS VECTORS\n",
    "\n",
    "\n",
    "vector_data, vector_feature_grids, all_feature_mappings, vector_geospatial_info_list = geojson_to_numpy_grid_3d_batch(\n",
    "    grid_size, geojson_files, vector_features_to_process\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"Shape of the 3D grid array:\", vector_data.shape)\n",
    "print(\"Feature grids:\", vector_feature_grids.keys())\n",
    "print(\"Feature mappings:\", all_feature_mappings)\n",
    "print(\"Geospatial information for each file:\", vector_geospatial_info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLE SLIDER PLOT\n",
    "\n",
    "data_to_plot = vector_data\n",
    "\n",
    "# Initialize the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Function to plot a specific layer using Matplotlib\n",
    "def plot_layer_bokeh(layer_index):\n",
    "    # Create the plot\n",
    "    fig = Figure(figsize=(3, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(data_to_plot[layer_index], cmap='viridis', interpolation='nearest', aspect='auto')\n",
    "    ax.set_title(f\"Layer {layer_index + 1}\")\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "# Create a Bokeh slider widget for selecting the layer\n",
    "layer_slider = pn.widgets.IntSlider(name='Layer Index', start=0, end=data_to_plot.shape[0] - 1, step=1, value=0)\n",
    "\n",
    "# Bind the plotting function to the slider value\n",
    "panel = pn.bind(plot_layer_bokeh, layer_index=layer_slider)\n",
    "\n",
    "# Display the Panel with the slider and plot\n",
    "pn.Column(layer_slider, panel).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved in: C:/Users/TyHow/Documents/3. Work/ML_test_area/exports/800\n"
     ]
    }
   ],
   "source": [
    "#SAVE RASTER DATA\n",
    "\n",
    "# Hide the root window for file dialog\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "root.attributes(\"-topmost\", True)  # Bring the file dialog to the front\n",
    "\n",
    "# Prompt the user to select a folder to save the files\n",
    "output_directory = askdirectory(\n",
    "    initialdir=r\"C:\\Users\\TyHow\\Documents\\3. Work\\ML_test_area\\exports\",\n",
    "    title=\"Select a Folder to Save Output Files (BEWARE OVERWRITE!)\"\n",
    ")\n",
    "\n",
    "if output_directory:\n",
    "    # Construct file paths using the selected folder and default file names\n",
    "    output_6_rasters_file = os.path.join(output_directory, \"output_rasters.npy\")\n",
    "    output_6_rasters_layer_mappings_file = os.path.join(output_directory, \"output_rasters_layer_mappings.npy\")\n",
    "\n",
    "    # Save the files\n",
    "    np.save(output_6_rasters_file, raster_data)\n",
    "    np.save(output_6_rasters_layer_mappings_file, raster_feature_mappings)\n",
    "\n",
    "    print(f\"Files saved in: {output_directory}\")\n",
    "\n",
    "# Destroy the root window after file dialogs are closed\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved in: C:/Users/TyHow/Documents/3. Work/ML_test_area/exports/800\n"
     ]
    }
   ],
   "source": [
    "#SAVE VECTOR DATA\n",
    "\n",
    "# Hide the root window for file dialog\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "root.attributes(\"-topmost\", True)  # Bring the file dialog to the front\n",
    "\n",
    "# Prompt the user to select a folder to save the files\n",
    "output_directory = askdirectory(\n",
    "    initialdir=r\"C:\\Users\\TyHow\\Documents\\3. Work\\ML_test_area\\exports\",\n",
    "    title=\"Select a Folder to Save Output Files (BEWARE OVERWRITE!)\"\n",
    ")\n",
    "\n",
    "if output_directory:\n",
    "    # Construct file paths using the selected folder and default file names\n",
    "    output_array_file = os.path.join(output_directory, \"output_vectors.npy\")\n",
    "    output_feature_grid_file = os.path.join(output_directory, \"output_vector_feature_grid.npy\")\n",
    "    output_feature_mappings_file = os.path.join(output_directory, \"output_vector_feature_mappings.npy\")\n",
    "    output_geospatial_info_file = os.path.join(output_directory, \"output_vector_geospatial_info.npy\")\n",
    "\n",
    "    # Save the files\n",
    "    np.save(output_array_file, vector_data)\n",
    "    np.save(output_feature_grid_file, vector_feature_grids)\n",
    "    np.save(output_feature_mappings_file, all_feature_mappings)\n",
    "    np.save(output_geospatial_info_file, vector_geospatial_info_list)\n",
    "\n",
    "    print(f\"Files saved in: {output_directory}\")\n",
    "\n",
    "# Destroy the root window after file dialogs are closed\n",
    "root.destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NETCDF AS ARRAY\n",
    "\n",
    "# Function to prompt the user to select a .nc file\n",
    "def select_nc_file():\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "    # Open a file selection dialog\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select NetCDF File\",\n",
    "        filetypes=[(\"NetCDF files\", \"*.nc\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "\n",
    "    root.destroy()  # Close the root window after file selection\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# Function to convert a NetCDF file to a NumPy array\n",
    "def nc_to_numpy(file_path):\n",
    "    try:\n",
    "        # Load the NetCDF file using xarray\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Display available variables\n",
    "        print(\"Variables available in the NetCDF file:\")\n",
    "        for var in ds.data_vars:\n",
    "            print(var)\n",
    "        \n",
    "        # Select the variable to convert to NumPy array (adjust as needed)\n",
    "        var_name = input(\"Enter the variable name to convert to NumPy array: \")\n",
    "\n",
    "        if var_name in ds:\n",
    "            # Extract the variable and convert it to a NumPy array\n",
    "            data_array = ds[var_name].values\n",
    "            print(f\"Successfully converted {var_name} to a NumPy array with shape {data_array.shape}\")\n",
    "            return data_array\n",
    "        else:\n",
    "            print(f\"Variable '{var_name}' not found in the NetCDF file.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading NetCDF file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 1: Select the NetCDF file\n",
    "selected_file = select_nc_file()\n",
    "\n",
    "if selected_file:\n",
    "    print(f\"Selected file: {selected_file}\")\n",
    "    \n",
    "    # Step 2: Convert the selected NetCDF file to a NumPy array\n",
    "    nc_array = nc_to_numpy(selected_file)\n",
    "    \n",
    "    if nc_array is not None:\n",
    "        print(f\"Converted NumPy array shape: {nc_array.shape}\")\n",
    "else:\n",
    "    print(\"No file selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPLACE combined_data WITH IMPORTED .NC ARRAY\n",
    "combined_data = nc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined array shape: (12, 1033, 800)\n",
      "Layer Name Mapping List: ['geology_clipped_fid', 'geology_clipped_SUBTIPO_DE', 'geology_clipped_CODIGO', 'geology_clipped_DEFINICION', 'geology_clipped_UNIDAD_GEN', 'M162-Deposits_CLIPPED_fid', 'alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED', 'argz_indices_1340_test_larger_area_CLIPPED', 'bsi_indices_1340_test_larger_area_CLIPPED', 'clay_minerals_indices_1340_test_larger_area_CLIPPED', 'goethite_s2_copper_sam_1340_test_larger_area_CLIPPED', 'illite_indices_1340_test_larger_area_CLIPPED']\n",
      "Layer name mapping successful. Total layers: 12\n"
     ]
    }
   ],
   "source": [
    "# COMBINE ARRAYS - WITH LAYER NAMES\n",
    "\n",
    "# Combine the arrays (vector and raster)\n",
    "if vector_data.shape[1:] == raster_data.shape[1:]:\n",
    "    combined_data = np.concatenate((vector_data, raster_data), axis=0)\n",
    "    print(f\"Combined array shape: {combined_data.shape}\")\n",
    "\n",
    "    # Initialize the layer name mapping list\n",
    "    combined_layer_names = []\n",
    "\n",
    "    # Add vector layer names (from feature names in vector_feature_grids) first\n",
    "    for vector_feature_name in vector_feature_grids.keys():\n",
    "        combined_layer_names.append(vector_feature_name)\n",
    "\n",
    "    # Add raster layer names (from file names) after the vector layer names\n",
    "    for raster_name in raster_names:\n",
    "        combined_layer_names.append(raster_name)\n",
    "\n",
    "    # Check the mapping to ensure it is correct\n",
    "    print(\"Layer Name Mapping List:\", combined_layer_names)\n",
    "\n",
    "    # Ensure the combined_data layers match the number of names\n",
    "    if len(combined_layer_names) == combined_data.shape[0]:\n",
    "        print(f\"Layer name mapping successful. Total layers: {len(combined_layer_names)}\")\n",
    "    else:\n",
    "        print(f\"Warning: Mismatch in layers. {len(combined_layer_names)} names for {combined_data.shape[0]} layers.\")\n",
    "else:\n",
    "    print(\"Error: The x/y dimensions of the arrays do not match.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='b3aabb02-9bac-4830-a7d8-43863e3ab924'>\n",
       "  <div id=\"c979ba76-b083-493e-9fe2-dc8cdaf10fb8\" data-root-id=\"b3aabb02-9bac-4830-a7d8-43863e3ab924\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"b4e8549a-6678-4b0d-a3d5-29abbb9c4048\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"b3aabb02-9bac-4830-a7d8-43863e3ab924\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"f87d71d9-aeaa-4001-b3f6-abb651cff5f3\",\"attributes\":{\"plot_id\":\"b3aabb02-9bac-4830-a7d8-43863e3ab924\",\"comm_id\":\"4dac5b80dda14b65b4ac457f1e4d64b3\",\"client_comm_id\":\"a6ee14584fb84b1e899b9a38764fc1a1\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"b4e8549a-6678-4b0d-a3d5-29abbb9c4048\",\"roots\":{\"b3aabb02-9bac-4830-a7d8-43863e3ab924\":\"c979ba76-b083-493e-9fe2-dc8cdaf10fb8\"},\"root_ids\":[\"b3aabb02-9bac-4830-a7d8-43863e3ab924\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "b3aabb02-9bac-4830-a7d8-43863e3ab924"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c75c2894a54ea1bf997eb031ef51cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'40d4189d-8988-49ca-8563-716ff9261e4b': {'version…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PLOT COMBINED - with layer names\n",
    "\n",
    "data_to_plot = combined_data\n",
    "\n",
    "# Initialize the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Assuming combined_layer_names is a list that stores the names of each layer\n",
    "# combined_layer_names should be the list that maps to each layer of the combined_data array\n",
    "\n",
    "# Function to plot a specific layer using Matplotlib\n",
    "def plot_layer_bokeh(layer_index):\n",
    "    # Create the plot\n",
    "    fig = Figure(figsize=(3, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(data_to_plot[layer_index], cmap='viridis', interpolation='nearest', aspect='auto')\n",
    "    \n",
    "    # Use combined_layer_names for the title\n",
    "    ax.set_title(f\"Layer {layer_index + 1}: {combined_layer_names[layer_index]}\")\n",
    "    \n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "# Create a Bokeh slider widget for selecting the layer\n",
    "layer_slider = pn.widgets.IntSlider(name='Layer Index', start=0, end=data_to_plot.shape[0] - 1, step=1, value=0)\n",
    "\n",
    "# Bind the plotting function to the slider value\n",
    "panel = pn.bind(plot_layer_bokeh, layer_index=layer_slider)\n",
    "\n",
    "# Display the Panel with the slider and plot\n",
    "pn.Column(layer_slider, panel).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO XARRAY\n",
    "\n",
    "# Create dummy arrays for X, Y coordinates (you can replace these with your actual coordinates)\n",
    "x_coords = np.arange(combined_data.shape[2])  # X-coordinates (along the third axis)\n",
    "y_coords = np.arange(combined_data.shape[1])  # Y-coordinates (along the second axis)\n",
    "layer_names = combined_layer_names  # Layer names\n",
    "\n",
    "# Create an xarray DataArray from the combined NumPy array\n",
    "data_xr = xr.DataArray(\n",
    "    combined_data, \n",
    "    dims=[\"layer\", \"y\", \"x\"], \n",
    "    coords={\"layer\": layer_names, \"y\": y_coords, \"x\": x_coords},\n",
    "    name=\"combined_layers\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully exported to C:/Users/TyHow/Documents/3. Work/ML_test_area/exports/800/THE_CUBE.nc\n"
     ]
    }
   ],
   "source": [
    "#EXPORT XARRAY TO NETCDF\n",
    "\n",
    "# Hide the root window for the file dialog\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the main window\n",
    "root.attributes(\"-topmost\", True)  # Bring the file dialog to the front\n",
    "\n",
    "# Prompt the user to select a location to save the NetCDF file\n",
    "output_file = asksaveasfilename(\n",
    "    initialfile=\"THE_CUBE.nc\",  # Default file name\n",
    "    defaultextension=\".nc\",  # Default extension\n",
    "    filetypes=[(\"NetCDF files\", \"*.nc\"), (\"All files\", \"*.*\")],\n",
    "    title=\"Save NetCDF file\"\n",
    ")\n",
    "\n",
    "# If the user provides a location, save the NetCDF file\n",
    "if output_file:\n",
    "    data_xr.to_netcdf(output_file)\n",
    "    print(f\"Data successfully exported to {output_file}\")\n",
    "\n",
    "# Destroy the root window after file dialog is closed\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CHECKERBOARD FUNCTION\n",
    "def checkerboard_data(data: np.ndarray, points_of_interest: np.ndarray, square_size: tuple[int, int]) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Apply checkerboard pattern to the data and split into two sets (checker 0 and checker 1).\n",
    "    \n",
    "    Parameters:\n",
    "        data (np.ndarray): The 3D data array (layers, y, x).\n",
    "        points_of_interest (np.ndarray): The 2D binary array corresponding to points of interest (y, x).\n",
    "        square_size (tuple[int, int]): Size of each checkerboard square.\n",
    "    \n",
    "    Returns:\n",
    "        X_check0, y_check0, X_check1, y_check1: Checkerboarded and NaN-removed datasets.\n",
    "    \"\"\"\n",
    "    # Check dimensions to ensure the spatial dimensions of data and points_of_interest match\n",
    "    if points_of_interest.shape != (data.shape[1], data.shape[2]):\n",
    "        raise ValueError(\"Points of interest and data spatial dimensions (y, x) do not match.\")\n",
    "    \n",
    "    # Flatten spatial dimensions of the data for easier manipulation\n",
    "    X_pix = data.reshape((data.shape[0], data.shape[1] * data.shape[2])).T\n",
    "    y_pix = points_of_interest.flatten()\n",
    "\n",
    "    # Debug: Print data shapes after reshaping\n",
    "    print(f\"X_pix shape: {X_pix.shape}\")\n",
    "    print(f\"y_pix shape: {y_pix.shape}\")\n",
    "\n",
    "    # Remove NaNs from the points_of_interest and corresponding data\n",
    "    X = X_pix[~np.isnan(y_pix)]\n",
    "    y = y_pix[~np.isnan(y_pix)]\n",
    "\n",
    "    print(f\"Shape of data after removing NaNs (X): {X.shape}\")\n",
    "    print(f\"Shape of points of interest after removing NaNs (y): {y.shape}\")\n",
    "\n",
    "    # Create checkerboard pattern\n",
    "    checker = make_checkerboard((data.shape[1], data.shape[2]), square_size)\n",
    "\n",
    "    # Debug: Print checkerboard shape and flattened shape\n",
    "    print(f\"Checkerboard shape: {checker.shape}\")\n",
    "    print(f\"Checkerboard flattened shape: {checker.flatten().shape}\")\n",
    "\n",
    "    # Split data based on checkerboard pattern\n",
    "    X_check0 = X_pix[checker.flatten() == 0]\n",
    "    y_check0 = y_pix[checker.flatten() == 0]\n",
    "\n",
    "    X_check1 = X_pix[checker.flatten() == 1]\n",
    "    y_check1 = y_pix[checker.flatten() == 1]\n",
    "\n",
    "    # Debug: Print shapes of split data\n",
    "    print(f\"Checker 0 data shape: {X_check0.shape}, Checker 1 data shape: {X_check1.shape}\")\n",
    "    print(f\"Checker 0 labels shape: {y_check0.shape}, Checker 1 labels shape: {y_check1.shape}\")\n",
    "\n",
    "    # Remove NaNs from each checker set\n",
    "    X_check0 = X_check0[~np.isnan(y_check0)]\n",
    "    y_check0 = y_check0[~np.isnan(y_check0)]\n",
    "\n",
    "    X_check1 = X_check1[~np.isnan(y_check1)]\n",
    "    y_check1 = y_check1[~np.isnan(y_check1)]\n",
    "\n",
    "    # Print final details\n",
    "    print(f'\\nChecker 0: X data array shape is {X_check0.shape}, y points of interest array shape is {y_check0.shape}')\n",
    "    print(f'Checker 1: X data array shape is {X_check1.shape}, y points of interest array shape is {y_check1.shape}')\n",
    "\n",
    "    return X_check0, y_check0, X_check1, y_check1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The inputs for board_size or square_size are not the same. This may result in a non-square checkerboard.\n",
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n",
      "[0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20f0a7dffb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST GENERATE CHECKERBOARD\n",
    "board_size = (combined_data.shape[1], combined_data.shape[2])  # Adjust based on the size of your data grid (y, x)\n",
    "square_size = (200, 200)   # Size of the checkerboard squares\n",
    "\n",
    "checker = make_checkerboard(board_size, square_size)\n",
    "print(checker)  # Print the checkerboard pattern\n",
    "print(np.unique(checker.flatten()))  # This should return [0, 1]\n",
    "\n",
    "plt.imshow(checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_pix shape: (826400, 12)\n",
      "y_pix shape: (826400,)\n",
      "Shape of data after removing NaNs (X): (826400, 12)\n",
      "Shape of points of interest after removing NaNs (y): (826400,)\n",
      "Warning: The inputs for board_size or square_size are not the same. This may result in a non-square checkerboard.\n",
      "Checkerboard shape: (1033, 800)\n",
      "Checkerboard flattened shape: (826400,)\n",
      "Checker 0 data shape: (413200, 12), Checker 1 data shape: (413200, 12)\n",
      "Checker 0 labels shape: (413200,), Checker 1 labels shape: (413200,)\n",
      "\n",
      "Checker 0: X data array shape is (413200, 12), y points of interest array shape is (413200,)\n",
      "Checker 1: X data array shape is (413200, 12), y points of interest array shape is (413200,)\n",
      "Checker 0: X data array shape is (413200, 12), y points of interest array shape is (413200,)\n",
      "Checker 1: X data array shape is (413200, 12), y points of interest array shape is (413200,)\n"
     ]
    }
   ],
   "source": [
    "# CHECKER DATA\n",
    "target_layer = 4\n",
    "square_size = (200, 200)   # Size of the checkerboard squares\n",
    "\n",
    "points_of_interest = combined_data[target_layer]\n",
    "X_check0, y_check0, X_check1, y_check1 = checkerboard_data(combined_data, points_of_interest, square_size)\n",
    "\n",
    "# After running the function, check the output\n",
    "print(f'Checker 0: X data array shape is {X_check0.shape}, y points of interest array shape is {y_check0.shape}')\n",
    "print(f'Checker 1: X data array shape is {X_check1.shape}, y points of interest array shape is {y_check1.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAMES FUNCTION\n",
    "\n",
    "def create_dataframes(combined_data: np.ndarray, X_check0: np.ndarray, y_check0: np.ndarray, \n",
    "                      X_check1: np.ndarray, y_check1: np.ndarray, combined_layer_names: list, \n",
    "                      all_feature_mappings: Dict[str, Dict[Any, int]], target_layer: int) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create 3 pandas DataFrames based on combined_data and checkerboard data:\n",
    "    1) Complete DataFrame with categories converted back from integer values for categorical layers,\n",
    "       and the target layer removed.\n",
    "    2) Checkerboard 0 DataFrame with categories converted back from integer values for categorical layers,\n",
    "       and including the target layer.\n",
    "    3) Checkerboard 1 DataFrame with categories converted back from integer values for categorical layers,\n",
    "       and including the target layer.\n",
    "    \n",
    "    Parameters:\n",
    "        combined_data (np.ndarray): The complete 3D array of data (layers, y, x).\n",
    "        X_check0 (np.ndarray): The checkerboard 0 data array (including the target).\n",
    "        y_check0 (np.ndarray): The target data for checkerboard 0.\n",
    "        X_check1 (np.ndarray): The checkerboard 1 data array (including the target).\n",
    "        y_check1 (np.ndarray): The target data for checkerboard 1.\n",
    "        combined_layer_names (list): The list of layer names in the order they appear in combined_data.\n",
    "        all_feature_mappings (Dict[str, Dict[Any, int]]): The mapping of categorical data to integers.\n",
    "        target_layer (int): The index of the target layer to be removed from the complete DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        complete_df_with_categories (pd.DataFrame): The complete DataFrame with categories converted back,\n",
    "                                                    and without the target layer.\n",
    "        checker0_df_with_categories (pd.DataFrame): The checkerboard 0 DataFrame with categories converted back,\n",
    "                                                    and with the target layer included.\n",
    "        checker1_df_with_categories (pd.DataFrame): The checkerboard 1 DataFrame with categories converted back,\n",
    "                                                    and with the target layer included.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Complete DataFrame with categories converted back, and the target layer removed\n",
    "    # Remove the target layer from combined_data\n",
    "    data_no_target = np.delete(combined_data, target_layer, axis=0)\n",
    "    layer_names_no_target = [name for i, name in enumerate(combined_layer_names) if i != target_layer]\n",
    "\n",
    "    data_no_target_flattened = data_no_target.reshape(data_no_target.shape[0], -1).T  # Flatten the spatial dims\n",
    "    complete_df_with_categories = pd.DataFrame()\n",
    "\n",
    "    # Loop through each layer (excluding the target) and check if it's categorical\n",
    "    for layer_idx, layer_name in enumerate(layer_names_no_target):\n",
    "        if layer_name in all_feature_mappings:\n",
    "            # Reverse the integer-to-category mapping\n",
    "            int_to_category = {v: k for k, v in all_feature_mappings[layer_name].items()}\n",
    "            # Map the flattened integer data back to categories\n",
    "            complete_df_with_categories[layer_name] = pd.Series(data_no_target_flattened[:, layer_idx]).map(int_to_category)\n",
    "        else:\n",
    "            # If the layer is numerical, just add it to the DataFrame as is\n",
    "            complete_df_with_categories[layer_name] = data_no_target_flattened[:, layer_idx]\n",
    "\n",
    "    print(f\"Complete DataFrame with categories (no target) shape: {complete_df_with_categories.shape}\")\n",
    "\n",
    "    # 2. Checkerboard 0 DataFrame (data already includes the target)\n",
    "    checker0_df_with_categories = pd.DataFrame()\n",
    "\n",
    "    for layer_idx, layer_name in enumerate(combined_layer_names):\n",
    "        if layer_name in all_feature_mappings:\n",
    "            # Reverse the integer-to-category mapping\n",
    "            int_to_category = {v: k for k, v in all_feature_mappings[layer_name].items()}\n",
    "            # Map the checker0 integer data back to categories\n",
    "            checker0_df_with_categories[layer_name] = pd.Series(X_check0[:, layer_idx]).map(int_to_category)\n",
    "        else:\n",
    "            # If the layer is numerical, just add it to the DataFrame as is\n",
    "            checker0_df_with_categories[layer_name] = X_check0[:, layer_idx]\n",
    "\n",
    "    print(f\"Checkerboard 0 DataFrame with categories shape: {checker0_df_with_categories.shape}\")\n",
    "\n",
    "    # 3. Checkerboard 1 DataFrame (data already includes the target)\n",
    "    checker1_df_with_categories = pd.DataFrame()\n",
    "\n",
    "    for layer_idx, layer_name in enumerate(combined_layer_names):\n",
    "        if layer_name in all_feature_mappings:\n",
    "            # Reverse the integer-to-category mapping\n",
    "            int_to_category = {v: k for k, v in all_feature_mappings[layer_name].items()}\n",
    "            # Map the checker1 integer data back to categories\n",
    "            checker1_df_with_categories[layer_name] = pd.Series(X_check1[:, layer_idx]).map(int_to_category)\n",
    "        else:\n",
    "            # If the layer is numerical, just add it to the DataFrame as is\n",
    "            checker1_df_with_categories[layer_name] = X_check1[:, layer_idx]\n",
    "\n",
    "    print(f\"Checkerboard 1 DataFrame with categories shape: {checker1_df_with_categories.shape}\")\n",
    "\n",
    "    return complete_df_with_categories, checker0_df_with_categories, checker1_df_with_categories\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete DataFrame with categories (no target) shape: (826400, 11)\n",
      "Checkerboard 0 DataFrame with categories shape: (413200, 12)\n",
      "Checkerboard 1 DataFrame with categories shape: (413200, 12)\n",
      "   geology_clipped_fid geology_clipped_SUBTIPO_DE geology_clipped_CODIGO  \\\n",
      "0                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "1                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "2                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "3                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "4                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "\n",
      "                          geology_clipped_DEFINICION  \\\n",
      "0  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "1  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "2  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "3  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "4  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "\n",
      "  M162-Deposits_CLIPPED_fid  \\\n",
      "0                       NaN   \n",
      "1                       NaN   \n",
      "2                       NaN   \n",
      "3                       NaN   \n",
      "4                       NaN   \n",
      "\n",
      "   alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED  \\\n",
      "0                                           0.974407        \n",
      "1                                           0.966602        \n",
      "2                                           0.964086        \n",
      "3                                           0.963025        \n",
      "4                                                NaN        \n",
      "\n",
      "   argz_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                    2.302477   \n",
      "1                                    2.309272   \n",
      "2                                    2.258767   \n",
      "3                                    2.318627   \n",
      "4                                    0.000000   \n",
      "\n",
      "   bsi_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                   0.090798   \n",
      "1                                   0.111945   \n",
      "2                                   0.127890   \n",
      "3                                   0.143872   \n",
      "4                                   0.000000   \n",
      "\n",
      "   clay_minerals_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                                NaN     \n",
      "1                                                NaN     \n",
      "2                                                NaN     \n",
      "3                                                NaN     \n",
      "4                                                NaN     \n",
      "\n",
      "   goethite_s2_copper_sam_1340_test_larger_area_CLIPPED  \\\n",
      "0                                           0.888819      \n",
      "1                                           0.897882      \n",
      "2                                           0.894550      \n",
      "3                                           0.896695      \n",
      "4                                                NaN      \n",
      "\n",
      "   illite_indices_1340_test_larger_area_CLIPPED  \n",
      "0                                           NaN  \n",
      "1                                           NaN  \n",
      "2                                           NaN  \n",
      "3                                           NaN  \n",
      "4                                           NaN  \n",
      "   geology_clipped_fid geology_clipped_SUBTIPO_DE geology_clipped_CODIGO  \\\n",
      "0                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "1                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "2                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "3                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "4                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "\n",
      "                          geology_clipped_DEFINICION  \\\n",
      "0  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "1  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "2  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "3  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "4  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "\n",
      "  geology_clipped_UNIDAD_GEN M162-Deposits_CLIPPED_fid  \\\n",
      "0                  KPadp(gd)                       NaN   \n",
      "1                  KPadp(gd)                       NaN   \n",
      "2                  KPadp(gd)                       NaN   \n",
      "3                  KPadp(gd)                       NaN   \n",
      "4                  KPadp(gd)                       NaN   \n",
      "\n",
      "   alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED  \\\n",
      "0                                           0.974407        \n",
      "1                                           0.966602        \n",
      "2                                           0.964086        \n",
      "3                                           0.963025        \n",
      "4                                                NaN        \n",
      "\n",
      "   argz_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                    2.302477   \n",
      "1                                    2.309272   \n",
      "2                                    2.258767   \n",
      "3                                    2.318627   \n",
      "4                                    0.000000   \n",
      "\n",
      "   bsi_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                   0.090798   \n",
      "1                                   0.111945   \n",
      "2                                   0.127890   \n",
      "3                                   0.143872   \n",
      "4                                   0.000000   \n",
      "\n",
      "   clay_minerals_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                                NaN     \n",
      "1                                                NaN     \n",
      "2                                                NaN     \n",
      "3                                                NaN     \n",
      "4                                                NaN     \n",
      "\n",
      "   goethite_s2_copper_sam_1340_test_larger_area_CLIPPED  \\\n",
      "0                                           0.888819      \n",
      "1                                           0.897882      \n",
      "2                                           0.894550      \n",
      "3                                           0.896695      \n",
      "4                                                NaN      \n",
      "\n",
      "   illite_indices_1340_test_larger_area_CLIPPED  \n",
      "0                                           NaN  \n",
      "1                                           NaN  \n",
      "2                                           NaN  \n",
      "3                                           NaN  \n",
      "4                                           NaN  \n",
      "   geology_clipped_fid geology_clipped_SUBTIPO_DE geology_clipped_CODIGO  \\\n",
      "0                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "1                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "2                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "3                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "4                   83         AMBIENTE PLUTONICO              KPadp(gd)   \n",
      "\n",
      "                          geology_clipped_DEFINICION  \\\n",
      "0  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "1  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "2  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "3  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "4  Facie de la Diorita Pichasca compuesta por gra...   \n",
      "\n",
      "  geology_clipped_UNIDAD_GEN M162-Deposits_CLIPPED_fid  \\\n",
      "0                  KPadp(gd)         Point of Interest   \n",
      "1                  KPadp(gd)         Point of Interest   \n",
      "2                  KPadp(gd)         Point of Interest   \n",
      "3                  KPadp(gd)                       NaN   \n",
      "4                  KPadp(gd)                       NaN   \n",
      "\n",
      "   alunite_emit_copper_mtmf_1340_test_larger_area_CLIPPED  \\\n",
      "0                                                NaN        \n",
      "1                                                NaN        \n",
      "2                                                NaN        \n",
      "3                                                NaN        \n",
      "4                                                NaN        \n",
      "\n",
      "   argz_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                         0.0   \n",
      "1                                         0.0   \n",
      "2                                         0.0   \n",
      "3                                         0.0   \n",
      "4                                         0.0   \n",
      "\n",
      "   bsi_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                        0.0   \n",
      "1                                        0.0   \n",
      "2                                        0.0   \n",
      "3                                        0.0   \n",
      "4                                        0.0   \n",
      "\n",
      "   clay_minerals_indices_1340_test_larger_area_CLIPPED  \\\n",
      "0                                                NaN     \n",
      "1                                                NaN     \n",
      "2                                                NaN     \n",
      "3                                                NaN     \n",
      "4                                                NaN     \n",
      "\n",
      "   goethite_s2_copper_sam_1340_test_larger_area_CLIPPED  \\\n",
      "0                                                NaN      \n",
      "1                                                NaN      \n",
      "2                                                NaN      \n",
      "3                                                NaN      \n",
      "4                                                NaN      \n",
      "\n",
      "   illite_indices_1340_test_larger_area_CLIPPED  \n",
      "0                                           NaN  \n",
      "1                                           NaN  \n",
      "2                                           NaN  \n",
      "3                                           NaN  \n",
      "4                                           NaN  \n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATAFRAMES\n",
    "\n",
    "# Create the dataframes\n",
    "complete_df, checker0_df, checker1_df = create_dataframes(\n",
    "    combined_data, X_check0, y_check0, X_check1, y_check1, combined_layer_names, all_feature_mappings, target_layer\n",
    ")\n",
    "\n",
    "# Print out the first few rows to check\n",
    "print(complete_df.head())\n",
    "print(checker0_df.head())\n",
    "print(checker1_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames saved to directory: C:/Users/TyHow/Documents/3. Work/ML_test_area/exports/800/200check\n"
     ]
    }
   ],
   "source": [
    "#EXPORT DFS PARQUET\n",
    "\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "\n",
    "# Function to prompt the user for an output directory\n",
    "def select_output_directory():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "    output_dir = filedialog.askdirectory(title=\"Select Output Directory\")\n",
    "    root.destroy()\n",
    "    return output_dir\n",
    "\n",
    "# Export DataFrames to Parquet files in the selected directory\n",
    "def export_dfs_to_parquet(checker0_df: pd.DataFrame, checker1_df: pd.DataFrame, complete_df: pd.DataFrame):\n",
    "    output_dir = select_output_directory()\n",
    "    if not output_dir:\n",
    "        print(\"No directory selected. Exiting...\")\n",
    "        return\n",
    "    \n",
    "    # File paths for each DataFrame\n",
    "    checker0_file = os.path.join(output_dir, 'checker0_df.parquet')\n",
    "    checker1_file = os.path.join(output_dir, 'checker1_df.parquet')\n",
    "    complete_file = os.path.join(output_dir, 'complete_df.parquet')\n",
    "\n",
    "    # Save DataFrames to Parquet format\n",
    "    checker0_df.to_parquet(checker0_file, engine='pyarrow')\n",
    "    checker1_df.to_parquet(checker1_file, engine='pyarrow')\n",
    "    complete_df.to_parquet(complete_file, engine='pyarrow')\n",
    "    \n",
    "    print(f\"DataFrames saved to directory: {output_dir}\")\n",
    "\n",
    "# Example usage assuming checker0_df, checker1_df, and complete_df are already generated\n",
    "export_dfs_to_parquet(checker0_df, checker1_df, complete_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSPECT DF\n",
    "pd.set_option('display.max_rows', 10) \n",
    "#checker1_df['M162-Deposits_CLIPPED_fid']\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAIRPLOT TO COMPARE CHECK0/1\n",
    "\n",
    "def generate_multidimensional_pairplot_for_checker_data(checker0_df: pd.DataFrame, checker1_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generate a multidimensional seaborn pairplot comparing Checkerboard 0 and Checkerboard 1 DataFrames,\n",
    "    focusing on numerical columns only.\n",
    "    \n",
    "    Parameters:\n",
    "        checker0_df (pd.DataFrame): DataFrame for Checkerboard 0.\n",
    "        checker1_df (pd.DataFrame): DataFrame for Checkerboard 1.\n",
    "    \"\"\"\n",
    "    # Add a column to each DataFrame indicating which checkerboard it belongs to\n",
    "    checker0_df['Checkerboard'] = 'Checkerboard 0'\n",
    "    checker1_df['Checkerboard'] = 'Checkerboard 1'\n",
    "\n",
    "    # Combine the two DataFrames\n",
    "    combined_df = pd.concat([checker0_df, checker1_df], ignore_index=True)\n",
    "\n",
    "    # Check which layers are available for plotting\n",
    "    print(f\"Columns available in combined DataFrame: {combined_df.columns}\")\n",
    "\n",
    "    # Filter out non-numerical (categorical) columns\n",
    "    numerical_columns = combined_df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    # Create the pairplot with hue based on 'Checkerboard'\n",
    "    sns.pairplot(combined_df, vars=numerical_columns, hue='Checkerboard', diag_kind='kde', palette=\"Set2\", markers=[\"o\", \"s\"], height=2.5)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "generate_multidimensional_pairplot_for_checker_data(checker0_df, checker1_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
