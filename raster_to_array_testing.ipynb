{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os  \n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import hvplot.xarray \n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from scipy.ndimage import generic_filter\n",
    "import cupy as cp\n",
    "from scipy.stats import mode\n",
    "from tkinter.filedialog import askopenfilenames\n",
    "from tkinter import Tk, filedialog, simpledialog\n",
    "from typing import Tuple \n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.transform import from_bounds\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "from matplotlib.figure import Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH GEOSPATIAL IMPORT - auto grid\n",
    "\n",
    "# Open a file selection dialog for the user to select multiple raster files\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "# Open the file selection dialog\n",
    "raster_files = askopenfilenames(\n",
    "    title=\"Select Raster Files\",\n",
    "    filetypes=[(\"GeoTIFF files\", \"*.tif\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "# Lists to store data and corresponding file names\n",
    "data = []  \n",
    "names = []\n",
    "\n",
    "# Determine the target grid size and transformation\n",
    "target_transform = None\n",
    "target_width = None\n",
    "target_height = None\n",
    "target_crs = None\n",
    "\n",
    "# First, determine the common CRS and the bounding box that covers all rasters\n",
    "for raster_file in raster_files:\n",
    "    with rasterio.open(raster_file, 'r') as src:\n",
    "        if target_crs is None:\n",
    "            target_crs = src.crs  # Use the CRS from the first raster\n",
    "        if target_transform is None:\n",
    "            target_transform = src.transform  # Use the transform from the first raster\n",
    "            target_width = src.width\n",
    "            target_height = src.height\n",
    "        else:\n",
    "            # Adjust the target bounding box to encompass the new raster\n",
    "            left, bottom, right, top = src.bounds\n",
    "            existing_bounds = rasterio.transform.array_bounds(target_height, target_width, target_transform)\n",
    "            new_bounds = (\n",
    "                min(existing_bounds[0], left), \n",
    "                min(existing_bounds[1], bottom), \n",
    "                max(existing_bounds[2], right), \n",
    "                max(existing_bounds[3], top)\n",
    "            )\n",
    "            target_transform, target_width, target_height = rasterio.warp.calculate_default_transform(\n",
    "                src.crs, target_crs, src.width, src.height, *new_bounds\n",
    "            )\n",
    "\n",
    "# Now, reproject and resample each raster to the common grid\n",
    "for raster_file in raster_files:\n",
    "    with rasterio.open(raster_file, 'r') as src:\n",
    "        # Prepare the output array\n",
    "        data_array = np.full((target_height, target_width), np.nan, dtype=np.float32)\n",
    "        \n",
    "        # Handle NoData value\n",
    "        nodata_value = src.nodata\n",
    "        if nodata_value is None:\n",
    "            nodata_value = np.nan  # If NoData is not set, assume NaN\n",
    "        \n",
    "        # Reproject the source data to the target grid\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=data_array,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=target_transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest,\n",
    "            src_nodata=nodata_value,  # Specify the source NoData value\n",
    "            dst_nodata=np.nan  # Use NaN as the destination NoData\n",
    "        )\n",
    "\n",
    "        # Append the resampled data and names to lists\n",
    "        data.append(data_array)  # Append the resampled data array\n",
    "        names.append(os.path.basename(raster_file).replace('.tif', ''))  # Append file name without extension\n",
    "\n",
    "# Stack list into a 3D numpy array\n",
    "data = np.stack(data, axis=0)  # Stack the list of arrays into a 3D numpy array\n",
    "#print(data)\n",
    "print(data.shape, names)\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    print(f\"Layer {i} ({names[i]}):\")\n",
    "    print(f\"  Min value: {np.nanmin(data[i])}\")\n",
    "    print(f\"  Max value: {np.nanmax(data[i])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE GRID SIZE FROM SHORT EDGE\n",
    "\n",
    "# Function to compute grid size based on the mask file\n",
    "def compute_grid_size(geojson_file: str, short_edge_cells: int = 20) -> Tuple[int, int]:\n",
    "    # Read the GeoJSON file using GeoPandas\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    \n",
    "    # Get the bounding box of the masking region\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    \n",
    "    # Calculate width and height of the bounding box\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    # Determine which is the short and long edge\n",
    "    if width < height:\n",
    "        short_edge = width\n",
    "        long_edge = height\n",
    "        orientation = 'portrait'\n",
    "    else:\n",
    "        short_edge = height\n",
    "        long_edge = width\n",
    "        orientation = 'landscape'\n",
    "\n",
    "    # Compute the aspect ratio\n",
    "    aspect_ratio = long_edge / short_edge\n",
    "\n",
    "    # Compute the number of cells for the long edge\n",
    "    long_edge_cells = int(short_edge_cells * aspect_ratio)\n",
    "\n",
    "    # Determine the grid size based on the orientation\n",
    "    if orientation == 'portrait':\n",
    "        grid_size = (short_edge_cells, long_edge_cells)\n",
    "    else:\n",
    "        grid_size = (long_edge_cells, short_edge_cells)\n",
    "\n",
    "    return grid_size\n",
    "\n",
    "# Prompt the user for the short_edge_cells value using tkinter\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "# Ask the user for the short edge size\n",
    "short_edge_cells = simpledialog.askinteger(\"Input\", \"Enter the number of cells for the short edge:\", minvalue=1)\n",
    "\n",
    "root.destroy()  # Close the tkinter root window\n",
    "\n",
    "if short_edge_cells is None:\n",
    "    raise ValueError(\"You must enter a valid number for the short edge size.\")\n",
    "\n",
    "# Set the mask file path\n",
    "mask_file = r\"C:\\Users\\TyHow\\Documents\\3. Work\\GIS Stuff\\ML_pilot_data\\MASK.geojson\"\n",
    "\n",
    "# Compute grid size using the mask file\n",
    "grid_size = compute_grid_size(mask_file, short_edge_cells=short_edge_cells)[::-1]\n",
    "print(f\"Calculated grid size: {grid_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS RASTERS TO DEFINED GRID with feature mappings\n",
    "\n",
    "# Get the bounding box of the mask file to use for target transform\n",
    "gdf = gpd.read_file(mask_file)\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "# Convert the GeoDataFrame to a projected CRS\n",
    "gdf = gdf.to_crs(\"EPSG:3857\")  # Project to a common projected CRS, e.g., EPSG:3857\n",
    "\n",
    "# Recalculate bounds in the projected CRS\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "# Compute the target transform for the projected CRS\n",
    "target_transform = from_bounds(minx, miny, maxx, maxy, grid_size[1], grid_size[0])\n",
    "target_crs = \"EPSG:3857\"  # Set the target CRS to a projected coordinate system\n",
    "\n",
    "# Open a file selection dialog for the user to select multiple raster files\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "# Open the file selection dialog\n",
    "raster_files = askopenfilenames(\n",
    "    title=\"Select Raster Files\",\n",
    "    filetypes=[(\"GeoTIFF files\", \"*.tif\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "# Lists to store data and corresponding file names\n",
    "data = []\n",
    "names = []\n",
    "feature_mappings = []  # List to store the mappings from filenames to their corresponding layers\n",
    "\n",
    "# Now, reproject and resample each raster to the common grid\n",
    "for layer_index, raster_file in enumerate(raster_files):\n",
    "    with rasterio.open(raster_file, 'r') as src:\n",
    "        print(f\"Processing file: {raster_file}\")\n",
    "        print(f\"Source CRS: {src.crs}\")\n",
    "        print(f\"Source Transform: {src.transform}\")\n",
    "        print(f\"Source Bounds: {src.bounds}\")\n",
    "\n",
    "        # Check if the source CRS matches the target CRS; reproject if needed\n",
    "        if src.crs != target_crs:\n",
    "            src_crs = src.crs\n",
    "        else:\n",
    "            src_crs = target_crs  # Keep the same CRS if already matching\n",
    "        \n",
    "        # Prepare the output array with NaN (representing no data)\n",
    "        data_array = np.full(grid_size, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Handle NoData value\n",
    "        nodata_value = src.nodata\n",
    "        if nodata_value is None:\n",
    "            nodata_value = np.nan  # If NoData is not set, assume NaN\n",
    "\n",
    "        # Print debug information\n",
    "        print(f\"Reprojecting {raster_file} to target grid...\")\n",
    "        print(f\"Target CRS: {target_crs}\")\n",
    "        print(f\"Target Transform: {target_transform}\")\n",
    "        print(f\"Target Grid Size: {grid_size}\")\n",
    "\n",
    "        # Reproject the source data to the target grid\n",
    "        reproject(\n",
    "            source=rasterio.band(src, 1),\n",
    "            destination=data_array,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=target_transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest,\n",
    "            src_nodata=nodata_value,\n",
    "            dst_nodata=np.nan  # Use NaN as the destination NoData\n",
    "        )\n",
    "\n",
    "        # Append the resampled data and names to lists\n",
    "        data.append(data_array)  # Append the resampled data array\n",
    "        file_name = os.path.basename(raster_file).replace('.tif', '')  # Get file name without extension\n",
    "        names.append(file_name)\n",
    "\n",
    "        # Append the filename to feature mappings with its corresponding layer index\n",
    "        feature_mappings.append((file_name, layer_index))\n",
    "\n",
    "# Stack list into a 3D numpy array\n",
    "data = np.stack(data, axis=0)  # Stack the list of arrays into a 3D numpy array\n",
    "print(data.shape, names)\n",
    "print(\"Feature Mappings:\", feature_mappings)  # Print the feature mappings\n",
    "\n",
    "# Check if all data layers contain NaN\n",
    "for i in range(data.shape[0]):\n",
    "    print(f\"Layer {i} ({names[i]}):\")\n",
    "    if np.all(np.isnan(data[i])):\n",
    "        print(\"  All values are NaN.\")\n",
    "    else:\n",
    "        print(f\"  Min value: {np.nanmin(data[i])}\")\n",
    "        print(f\"  Max value: {np.nanmax(data[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"C:\\Users\\TyHow\\Documents\\3. Work\\ML_test_area\\exports\\output_6_rasters\", data)\n",
    "np.save(r\"C:\\Users\\TyHow\\Documents\\3. Work\\ML_test_area\\exports\\output_6_rasters_layer_mappings\", feature_mappings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT\n",
    "plt.figure(figsize=(6, 8))\n",
    "\n",
    "layer = 0\n",
    "\n",
    "# Find the unique, non-NaN values in the data\n",
    "unique_classes = np.unique(data[layer][~np.isnan(data[layer])])\n",
    "\n",
    "# Create a colormap with a number of colors equal to the number of unique classes\n",
    "cmap = plt.get_cmap('tab20', len(unique_classes))\n",
    "\n",
    "# Plot the data using the correct colormap and normalization\n",
    "plt.imshow(data[layer], cmap=cmap, interpolation='nearest', aspect='auto')\n",
    "\n",
    "# Create a colorbar that matches the unique classes\n",
    "cbar = plt.colorbar(ticks=unique_classes)\n",
    "cbar.set_label('Classes')\n",
    "\n",
    "# Set colorbar ticks and labels to match the unique classes\n",
    "cbar.set_ticks(unique_classes)\n",
    "cbar.set_ticklabels([f'Class {int(cls)}' for cls in unique_classes])\n",
    "\n",
    "plt.title(f'{names[layer]}')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HANDLE NANS (often not needed, but can be used if the next block returns an error related to improper nans)\n",
    "\n",
    "# Convert \"nan\" strings to np.nan\n",
    "def preprocess_data(input_array):\n",
    "    # Convert input data to a NumPy array if not already\n",
    "    input_array = np.array(input_array)\n",
    "    \n",
    "    # Check if there are any string \"nan\" values and replace them with np.nan\n",
    "    input_array = np.where(input_array == \"nan\", np.nan, input_array)\n",
    "    \n",
    "    # Ensure the data is of a floating-point type to handle NaN values properly\n",
    "    input_array = input_array.astype(np.float32)\n",
    "    \n",
    "    return input_array\n",
    "\n",
    "\n",
    "# Preprocess data to handle \"nan\" strings\n",
    "data_preproc = preprocess_data(data)\n",
    "\n",
    "print(data_preproc)\n",
    "\n",
    "print(\"Data type of the array:\", data_preproc.dtype)\n",
    "\n",
    "\n",
    "num_valid_entries = np.sum(~np.isnan(data_preproc))\n",
    "print(f\"Number of valid entries in the data: {num_valid_entries}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH MEDIAN FILTER (CUDA) WITH PROPER EDGE HANDLING      ***only needed for categorical files created from semi-auto class or similar algorithms that create a lot of noise. DO NOT RUN ON NUMERICAL (e.g. remote sensing) DATA! \n",
    "\n",
    "# Define a custom CUDA kernel for the median filter\n",
    "median_filter_kernel = cp.RawKernel(r'''\n",
    "extern \"C\" __global__\n",
    "void median_filter(const float* input, float* output, int width, int height, int window_size) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    \n",
    "    int half_window = window_size / 2;\n",
    "    int window_elements = window_size * window_size;\n",
    "    float window[1024];  // Assuming max window size of 32x32 for simplicity\n",
    "\n",
    "    // Ensure the pixel is within bounds\n",
    "    if (x < width && y < height) {\n",
    "        int count = 0;\n",
    "\n",
    "        // Collect the neighboring pixels in the window\n",
    "        for (int i = -half_window; i <= half_window; ++i) {\n",
    "            for (int j = -half_window; j <= half_window; ++j) {\n",
    "                int nx = x + j;\n",
    "                int ny = y + i;\n",
    "\n",
    "                // Ensure the neighbor is within image bounds\n",
    "                if (nx >= 0 && nx < width && ny >= 0 && ny < height) {\n",
    "                    float val = input[ny * width + nx];\n",
    "                    if (!isnan(val)) {\n",
    "                        window[count] = val;\n",
    "                        count++;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Sort the collected values\n",
    "        for (int i = 0; i < count - 1; ++i) {\n",
    "            for (int j = i + 1; j < count; ++j) {\n",
    "                if (window[i] > window[j]) {\n",
    "                    float temp = window[i];\n",
    "                    window[i] = window[j];\n",
    "                    window[j] = temp;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Assign the median value\n",
    "        if (count > 0) {\n",
    "            output[y * width + x] = window[count / 2];\n",
    "        } else {\n",
    "            output[y * width + x] = __int_as_float(0x7fffffff);  // NaN in CUDA\n",
    "        }\n",
    "    }\n",
    "}\n",
    "''', 'median_filter')\n",
    "\n",
    "# Define the block and grid size\n",
    "block_size = (16, 16)  # Define a block size of 16x16\n",
    "\n",
    "# Define the smoothing window size\n",
    "window_size = 20  # Adjust window size as needed\n",
    "\n",
    "# Prepare an output array for all layers\n",
    "smoothed_data = np.empty_like(data)\n",
    "\n",
    "# Iterate over each layer in the 3D array\n",
    "for i in range(data.shape[0]):\n",
    "    # Extract the 2D data layer from the 3D array\n",
    "    data_layer = data[i]  # Extract each layer from the 3D array\n",
    "\n",
    "    # Convert the data layer to a CuPy array\n",
    "    data_layer_gpu = cp.array(data_layer)\n",
    "\n",
    "    # Calculate the grid size for the current layer\n",
    "    grid_size = ((data_layer_gpu.shape[1] + block_size[0] - 1) // block_size[0],\n",
    "                 (data_layer_gpu.shape[0] + block_size[1] - 1) // block_size[1])\n",
    "\n",
    "    # Initialize the output array for the current layer on the GPU\n",
    "    output_gpu = cp.empty_like(data_layer_gpu)\n",
    "\n",
    "    # Launch the CUDA kernel for the current layer\n",
    "    median_filter_kernel(grid_size, block_size, (data_layer_gpu, output_gpu, data_layer_gpu.shape[1], data_layer_gpu.shape[0], window_size))\n",
    "\n",
    "    # Convert the filtered 2D data layer back to a 2D numpy array\n",
    "    smoothed_layer = cp.asnumpy(output_gpu)\n",
    "    \n",
    "    # Store the smoothed layer back into the 3D numpy array\n",
    "    smoothed_data[i] = smoothed_layer\n",
    "\n",
    "# The smoothed_data array now contains all filtered layers\n",
    "print(smoothed_data.shape)  # Should print the shape of the smoothed 3D array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT MULTI LAYER\n",
    "\n",
    "# Initialize the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Function to plot a specific layer using Matplotlib\n",
    "def plot_layer_with_classes(layer_index):\n",
    "    fig = Figure(figsize=(3, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Get the unique, non-NaN values in the data for the selected layer\n",
    "    smoothed_unique_classes = np.unique(smoothed_data[layer_index][~np.isnan(smoothed_data[layer_index])])\n",
    "    \n",
    "    # Create a colormap with a number of colors equal to the number of unique classes\n",
    "    cmap_smooth = plt.get_cmap('tab20', len(smoothed_unique_classes))\n",
    "    \n",
    "    # Plot the data using the correct colormap and normalization\n",
    "    im = ax.imshow(smoothed_data[layer_index], cmap=cmap_smooth, interpolation='nearest', aspect='auto')\n",
    "    \n",
    "    # Create a colorbar that matches the unique classes\n",
    "    cbar = fig.colorbar(im, ax=ax, ticks=smoothed_unique_classes)\n",
    "    cbar.set_label('Classes')\n",
    "    \n",
    "    # Set colorbar ticks and labels to match the unique classes\n",
    "    cbar.set_ticks(smoothed_unique_classes)\n",
    "    cbar.set_ticklabels([f'Class {int(cls)}' for cls in smoothed_unique_classes])\n",
    "    \n",
    "    ax.set_title(f'{names[layer_index]} (filtered)')\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "# Create a Panel widget for selecting the layer\n",
    "layer_slider = pn.widgets.IntSlider(name='Layer Index', start=0, end=smoothed_data.shape[0] - 1, step=1, value=0)\n",
    "\n",
    "# Bind the plotting function to the slider value\n",
    "panel = pn.bind(plot_layer_with_classes, layer_index=layer_slider)\n",
    "\n",
    "# Display the Panel with the slider and plot\n",
    "pn.Column(layer_slider, panel).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT XARRAY \n",
    "\n",
    "# Convert numpy array to an xarray DataArray using the existing names\n",
    "data_xr = xr.DataArray(\n",
    "    smoothed_data, \n",
    "    dims=[\"layer\", \"y\", \"x\"], \n",
    "    coords={\"layer\": names, \"y\": np.arange(smoothed_data.shape[1]), \"x\": np.arange(smoothed_data.shape[2])},\n",
    "    name=\"smoothed_layers\"\n",
    ")\n",
    "\n",
    "# Plot using xarray with hvplot, allowing easy navigation through layers\n",
    "plot = data_xr.hvplot.image(\n",
    "    x=\"x\", \n",
    "    y=\"y\", \n",
    "    groupby=\"layer\",  # Allows selecting different layers by name\n",
    "    cmap=\"tab20\", \n",
    "    colorbar=True, \n",
    "    title=\"Smoothed Layers\",\n",
    "    aspect='equal',  # Ensures that the aspect ratio is maintained\n",
    "    width=600,  # Set width to match matplotlib plot dimensions\n",
    "    height=800  # Set height to match matplotlib plot dimensions\n",
    ")\n",
    "\n",
    "# Display the interactive plot\n",
    "hvplot.show(plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT GEOTIFF\n",
    "# Ask the user to select the output folder\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "output_folder = filedialog.askdirectory(title=\"Select Output Folder for GeoTIFF Files\")\n",
    "\n",
    "# Export each layer of the smoothed data as an individual GeoTIFF\n",
    "for i in range(smoothed_data.shape[0]):\n",
    "    output_raster_map = os.path.join(output_folder, f\"filtered_output_layer_{i + 1}.tif\")\n",
    "\n",
    "    # Get the shape of the current layer\n",
    "    height, width = smoothed_data[i].shape\n",
    "\n",
    "    with rasterio.open(\n",
    "        output_raster_map,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,  # Number of bands\n",
    "        dtype='float32',\n",
    "        crs=target_crs,  # Use the CRS from the import step\n",
    "        transform=target_transform,  # Use the transform from the import step\n",
    "        nodata=np.nan  # Ensure proper NoData value\n",
    "    ) as dst:\n",
    "        # Convert NaN to the appropriate nodata value for GeoTIFF\n",
    "        layer_data = smoothed_data[i].copy()\n",
    "        layer_data[np.isnan(layer_data)] = dst.nodata  # Replace NaN with the nodata value\n",
    "\n",
    "        # Write the current layer to the GeoTIFF file\n",
    "        dst.write(layer_data, 1)\n",
    "\n",
    "    print(f\"Layer {i+1} exported to {output_raster_map}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
