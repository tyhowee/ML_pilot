{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4cQzsLCTEYg"
      },
      "source": [
        "Supervised ML Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-11pypnDRik",
        "outputId": "8f05eb0d-6a84-4d66-cbea-4cbb4d523176"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NVHOGDNGDS-V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xarray as xr\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YjdhjNgRDVJ-"
      },
      "outputs": [],
      "source": [
        "import catboost\n",
        "from catboost import CatBoostClassifier, Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRwQiJUVDaLJ",
        "outputId": "754fba5c-6a8a-4c45-8aa6-d6b780d9e206"
      },
      "outputs": [],
      "source": [
        "cd \"C:\\Users\\TyHow\\MinersAI Dropbox\\Tyler Howe\\ML_Pilot_Tyler_Data\\1200_2\\200px_dfs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYixMP6uDcmP",
        "outputId": "b8c17b93-5867-43bc-8c9b-9eb18aeabcfb"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9h5kCQ-LDziv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('checker0_df.parquet')\n",
        "df.drop('geology_clipped_UNIDAD_GEN', axis=1, inplace=True)\n",
        "\n",
        "df_test = pd.read_parquet('checker1_df.parquet')\n",
        "df_test.drop('geology_clipped_UNIDAD_GEN', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ouV9FIED5KF",
        "outputId": "abbd9ad2-a74c-4a10-d576-ab5ce4faf5bf"
      },
      "outputs": [],
      "source": [
        "# Step 2: Check which columns are not float\n",
        "non_float_columns = df.select_dtypes(exclude=['float64']).columns\n",
        "print(\"Non-float columns:\", non_float_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "btyRb_xOFpsT"
      },
      "outputs": [],
      "source": [
        "target_column = 'TARGETS'\n",
        "\n",
        "df[target_column] = (df[target_column]).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['TARGETS'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52tuXbFggx1J",
        "outputId": "994854a9-df0b-45b5-cb2d-3808e8bc75e4"
      },
      "outputs": [],
      "source": [
        "feature_columns = [col for col in df.columns if col != target_column]\n",
        "\n",
        "# Updated: Identify categorical columns (object dtype or categorical)\n",
        "categorical_features_indices = [i for i, col in enumerate(feature_columns)\n",
        "                                if df[col].dtype == 'object' or isinstance(df[col].dtype, pd.CategoricalDtype)]\n",
        "\n",
        "# Prepare features and target\n",
        "X_train = df[feature_columns]\n",
        "y_train = df[target_column]\n",
        "\n",
        "# Handle missing values in features\n",
        "# Fill missing numerical columns with 0\n",
        "numerical_columns = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "X_train.loc[:, numerical_columns] = X_train[numerical_columns].fillna(0)\n",
        "\n",
        "# Fill missing categorical columns with a placeholder like 'Unknown'\n",
        "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
        "X_train.loc[:, categorical_columns] = X_train[categorical_columns].fillna('Unknown') \n",
        "\n",
        "print(\"Unique values in the TARGETS column:\", y_train.unique())\n",
        "\n",
        "# Check if all missing values are filled\n",
        "print(\"Number of NANs in x_train:\", X_train.isnull().sum().sum())  # This should print 0\n",
        "\n",
        "\n",
        "\n",
        "# Ensure target is binary (0 or 1)\n",
        "assert set(y_train.unique()) == {0, 1}, \"Target variable is not binary (0 or 1)\"\n",
        "\n",
        "# Create Pool object for training data, specifying categorical features\n",
        "train_pool = Pool(X_train, y_train, cat_features=categorical_features_indices)\n",
        "\n",
        "# Create and train the CatBoost model\n",
        "model = CatBoostClassifier(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.1,\n",
        "    depth=3,\n",
        "    loss_function='Logloss',\n",
        "    auto_class_weights='Balanced',\n",
        "    random_seed=42,\n",
        "    cat_features=categorical_features_indices  # Specify categorical features here as well\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_pool,\n",
        "    verbose=200\n",
        ")\n",
        "\n",
        "# Print feature importances\n",
        "feature_importances = model.get_feature_importance(prettified=True)\n",
        "print(\"\\nFeature Importances:\")\n",
        "print(feature_importances)\n",
        "\n",
        "# Print categorical features\n",
        "print(\"\\nCategorical Features:\")\n",
        "print([feature_columns[i] for i in categorical_features_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYZvDjf6Tpx0"
      },
      "source": [
        "#### Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcShVd6PJ4of",
        "outputId": "545d893c-5a9b-4a06-e7f5-b289a7f650ed"
      },
      "outputs": [],
      "source": [
        "# Load your test data from the Parquet file\n",
        "df_test[target_column] = (df_test[target_column]).astype(int)\n",
        "\n",
        "\n",
        "# Ensure the feature columns match those used in training\n",
        "feature_columns = model.feature_names_\n",
        "\n",
        "# Prepare features and target for testing\n",
        "X_test = df_test[feature_columns]\n",
        "y_test = df_test[target_column]\n",
        "\n",
        "# Handle missing values in the test set (similar to what you did with the training data)\n",
        "X_test.loc[:, numerical_columns] = X_test[numerical_columns].fillna(0)\n",
        "X_test.loc[:, categorical_columns] = X_test[categorical_columns].fillna('Unknown')\n",
        "\n",
        "# Check for any remaining missing values in X_test and y_test\n",
        "print(f\"Missing values in X_test: {X_test.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in y_test: {y_test.isnull().sum()}\")\n",
        "\n",
        "\n",
        "# Check if there's only one class in y_test\n",
        "unique_classes = np.unique(y_test)\n",
        "if len(unique_classes) == 1:\n",
        "    print(f\"Warning: Only one class present in the test set: {unique_classes[0]}\")\n",
        "    single_class = unique_classes[0]\n",
        "else:\n",
        "    single_class = None\n",
        "\n",
        "# Identify categorical features (should match the training data)\n",
        "categorical_features_indices = model.get_cat_feature_indices()\n",
        "\n",
        "# Create test pool\n",
        "test_pool = Pool(X_test, y_test, cat_features=categorical_features_indices)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(test_pool)\n",
        "\n",
        "# Calculate and print metrics\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFhPVvovTuBp"
      },
      "source": [
        "## Trying to fit the entire dataset through"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ki0dUPdrFglp"
      },
      "outputs": [],
      "source": [
        "def get_proba_map(X_df, model, map_shape):\n",
        "    \"\"\"\n",
        "    Generates a probability map from input features using a trained model.\n",
        "\n",
        "    Parameters:\n",
        "    X_df (pd.DataFrame): A DataFrame containing the input features for prediction.\n",
        "    model (CatBoostClassifier): A trained CatBoost model.\n",
        "    map_shape (tuple): The desired shape of the output map (height, width).\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: A 2D array with the shape specified by map_shape, containing the predicted probabilities for each pixel.\n",
        "    \"\"\"\n",
        "    # Handle missing values before creating the Pool\n",
        "    # Fill missing numerical columns with 0\n",
        "    numerical_columns = X_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    X_df[numerical_columns] = X_df[numerical_columns].fillna(0)\n",
        "\n",
        "    # Fill missing categorical columns with a placeholder like 'Unknown'\n",
        "    categorical_columns = X_df.select_dtypes(include=['object']).columns\n",
        "    X_df[categorical_columns] = X_df[categorical_columns].fillna('Unknown')\n",
        "\n",
        "    # Identify string columns as categorical features\n",
        "    cat_features = X_df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    # Create a Pool object for CatBoost\n",
        "    pool = Pool(X_df, cat_features=cat_features)\n",
        "\n",
        "    # Get predictions from the model (probability of the positive class)\n",
        "    predictions = model.predict_proba(pool)[:, 1]\n",
        "\n",
        "    # Ensure the predictions can be reshaped into the desired map shape\n",
        "    expected_size = map_shape[0] * map_shape[1]\n",
        "    if len(predictions) != expected_size:\n",
        "        raise ValueError(f\"Prediction size ({len(predictions)}) does not match the expected size ({expected_size}).\")\n",
        "\n",
        "    # Reshape the predictions to the desired map shape\n",
        "    pred_ar = predictions.reshape(map_shape)\n",
        "\n",
        "    return pred_ar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "M9sc0-pDLuoQ"
      },
      "outputs": [],
      "source": [
        "df_complete = pd.read_parquet('complete_df.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lKM2GTw9P5BG"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_selected = df_complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HVDQFnQlL0uX"
      },
      "outputs": [],
      "source": [
        "# Determine the map shape\n",
        "# You need to specify the correct shape here. For example:\n",
        "map_height = 1550  # Replace with the actual height of your map\n",
        "map_width = 1200   # Replace with the actual width of your map\n",
        "map_shape = (map_height, map_width)\n",
        "\n",
        "# Generate probability map\n",
        "prob_map = get_proba_map(df_selected, model, map_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "GKLQRKR4SvxM",
        "outputId": "572f281b-cbb9-4876-b311-9ea66f715d79"
      },
      "outputs": [],
      "source": [
        "# Plot the probability map\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(prob_map, cmap='viridis')\n",
        "plt.colorbar(label='Probability')\n",
        "plt.title('Probability Map')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
