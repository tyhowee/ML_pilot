{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "from typing import Tuple, Dict, Any, List\n",
    "import panel as pn\n",
    "from matplotlib.figure import Figure\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilenames\n",
    "from tkinter import Tk, Toplevel, Button, Checkbutton, IntVar, Label, Frame, filedialog\n",
    "import cupy as cp\n",
    "import easygui\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from joblib import Parallel, delayed\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION DEFINITION - CPU (only works for geol layer)\n",
    "\n",
    "def geojson_to_numpy_grid_3d_batch(\n",
    "    grid_size: Tuple[int, int],  # Grid size for the output array\n",
    "    target_crs: str = \"EPSG:3857\"  # Web Mercator projection\n",
    ") -> Tuple[np.ndarray, Dict[str, np.ndarray], Dict[str, Dict[Any, int]], List[Dict[str, Any]]]:\n",
    "    # Open a file selection dialog for the user to select multiple GeoJSON files\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "    # Open the file selection dialog\n",
    "    geojson_files = askopenfilenames(\n",
    "        title=\"Select GeoJSON Files\",\n",
    "        filetypes=[(\"GeoJSON files\", \"*.geojson\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "\n",
    "    all_feature_grids = {}\n",
    "    all_feature_mappings = {}\n",
    "    geospatial_info_list = []\n",
    "\n",
    "    for geojson_file in geojson_files:\n",
    "        # Read the GeoJSON file\n",
    "        gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "        # Reproject to target CRS\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "\n",
    "        # Get the total bounds of all geometries\n",
    "        minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "        # Create a fixed-size grid\n",
    "        x = np.linspace(minx, maxx, grid_size[1] + 1)\n",
    "        y = np.linspace(miny, maxy, grid_size[0] + 1)\n",
    "\n",
    "        # Automatically extract all relevant feature columns, excluding geometry columns\n",
    "        feature_columns = [col for col in gdf.columns if col != gdf.geometry.name]\n",
    "\n",
    "        # Get the filename without extension for prefixing\n",
    "        filename_prefix = os.path.splitext(os.path.basename(geojson_file))[0]\n",
    "\n",
    "        # Dictionary to hold grids and category mappings for each feature column\n",
    "        feature_grids = {}\n",
    "        feature_mappings = {}\n",
    "\n",
    "        # Store geospatial information for each file\n",
    "        geospatial_info = {\n",
    "            'transform': (minx, miny, maxx, maxy),\n",
    "            'crs': target_crs,\n",
    "            'file_name': filename_prefix\n",
    "        }\n",
    "        geospatial_info_list.append(geospatial_info)\n",
    "\n",
    "        # Iterate over each feature column\n",
    "        for feature_column in feature_columns:\n",
    "            # Get unique categories and create a mapping to integers\n",
    "            unique_categories = gdf[feature_column].unique()\n",
    "            \n",
    "            # Prefix each feature class with the filename\n",
    "            category_to_int = {f\"{filename_prefix}_{cat}\": i for i, cat in enumerate(unique_categories)}\n",
    "\n",
    "            # Initialize the 2D NumPy array with -1 (representing no data)\n",
    "            grid = np.full(grid_size, -1, dtype=int)\n",
    "\n",
    "            # Create a spatial index for faster intersection checks\n",
    "            sindex = gdf.sindex\n",
    "\n",
    "            # Pre-compute cell geometries\n",
    "            cells = [box(x[j], y[i], x[j + 1], y[i + 1])\n",
    "                     for i in range(grid_size[0])\n",
    "                     for j in range(grid_size[1])]\n",
    "\n",
    "            # Vectorized operations for intersection\n",
    "            def process_cell(cell, possible_matches):\n",
    "                if possible_matches.empty:\n",
    "                    return -1\n",
    "                intersections = possible_matches.geometry.intersection(cell)\n",
    "                intersection_areas = intersections.area\n",
    "                largest_intersection_idx = intersection_areas.idxmax()\n",
    "                category = possible_matches.loc[largest_intersection_idx, feature_column]\n",
    "                return category_to_int[f\"{filename_prefix}_{category}\"]\n",
    "\n",
    "            # Iterate through each cell in the grid\n",
    "            for idx, cell in enumerate(cells):\n",
    "                i, j = divmod(idx, grid_size[1])\n",
    "\n",
    "                # Use the spatial index to find potential intersecting polygons\n",
    "                possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "                if not possible_matches_index:\n",
    "                    continue\n",
    "\n",
    "                # Check for actual intersection and assign the feature value\n",
    "                possible_matches = gdf.iloc[possible_matches_index]\n",
    "                grid[i, j] = process_cell(cell, possible_matches)\n",
    "\n",
    "            # Store the grid and category mapping for this feature\n",
    "            feature_grids[f\"{filename_prefix}_{feature_column}\"] = grid\n",
    "            feature_mappings[f\"{filename_prefix}_{feature_column}\"] = category_to_int\n",
    "\n",
    "        # Merge with all feature grids and mappings\n",
    "        all_feature_grids.update(feature_grids)\n",
    "        all_feature_mappings.update(feature_mappings)\n",
    "\n",
    "    # Stack all grids into a 3D array\n",
    "    grid_3d = np.stack(list(all_feature_grids.values()), axis=0)\n",
    "\n",
    "    return grid_3d, all_feature_grids, all_feature_mappings, geospatial_info_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL PROCESSING FUNCTION - CPU - HYBRID STRATEGY\n",
    "\n",
    "def process_cell(idx, cell, gdf, sindex, feature_column, category_to_int, filename_prefix):\n",
    "    \"\"\"\n",
    "    Process a single cell by finding intersections and determining the feature value.\n",
    "    \"\"\"\n",
    "    i, j = divmod(idx, grid_size[1])\n",
    "\n",
    "    # Use the spatial index to find potential intersecting polygons\n",
    "    possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "    if not possible_matches_index:\n",
    "        return i, j, np.nan  # No intersecting features, return NaN for no data\n",
    "\n",
    "    # Check for actual intersection and assign the feature value\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    if possible_matches.empty:\n",
    "        return i, j, np.nan\n",
    "\n",
    "    # Calculate intersections more precisely\n",
    "    intersections = possible_matches.geometry.intersection(cell)\n",
    "\n",
    "    # Consider all non-zero intersections\n",
    "    valid_intersections = intersections[intersections.area > 0]\n",
    "\n",
    "    if valid_intersections.empty:\n",
    "        return i, j, np.nan\n",
    "\n",
    "    # Determine strategy based on the number of intersecting features\n",
    "    if len(valid_intersections) > 5:  # Threshold for choosing strategy\n",
    "        # Many small polygons: Sum the areas for each unique category\n",
    "        areas_per_category = {}\n",
    "        for idx, intersection in enumerate(valid_intersections):\n",
    "            if not intersection.is_empty:\n",
    "                category = possible_matches.iloc[idx][feature_column]\n",
    "                category_key = f\"{filename_prefix}_{category}\"\n",
    "                if category_key not in areas_per_category:\n",
    "                    areas_per_category[category_key] = 0\n",
    "                areas_per_category[category_key] += intersection.area\n",
    "\n",
    "        # Choose the category with the largest cumulative area\n",
    "        if areas_per_category:\n",
    "            max_category = max(areas_per_category, key=areas_per_category.get)\n",
    "            return i, j, category_to_int[max_category]\n",
    "        else:\n",
    "            return i, j, np.nan  # Fallback to NaN\n",
    "\n",
    "    else:\n",
    "        # Few large polygons: Choose the largest single intersection by area\n",
    "        largest_intersection_idx = valid_intersections.area.idxmax()\n",
    "        category = possible_matches.loc[largest_intersection_idx, feature_column]\n",
    "        return i, j, category_to_int[f\"{filename_prefix}_{category}\"]\n",
    "\n",
    "def process_feature_column(geojson_file, feature_column, grid_size, target_crs, filename_prefix, x, y):\n",
    "    # Read the GeoJSON file\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "    # Reproject to target CRS\n",
    "    gdf = gdf.to_crs(target_crs)\n",
    "\n",
    "    # Get unique categories and create a mapping to integers\n",
    "    unique_categories = gdf[feature_column].unique()\n",
    "    category_to_int = {f\"{filename_prefix}_{cat}\": i for i, cat in enumerate(unique_categories)}\n",
    "\n",
    "    # Initialize the 2D NumPy array with NaN (representing no data)\n",
    "    grid = np.full(grid_size, np.nan)\n",
    "\n",
    "    # Create a spatial index for faster intersection checks\n",
    "    sindex = gdf.sindex\n",
    "\n",
    "    # Pre-compute cell geometries\n",
    "    cells = [box(x[j], y[i], x[j + 1], y[i + 1])\n",
    "             for i in range(grid_size[0])\n",
    "             for j in range(grid_size[1])]\n",
    "\n",
    "    # Use joblib to parallelize cell processing\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_cell)(\n",
    "        idx, cell, gdf, sindex, feature_column, category_to_int, filename_prefix\n",
    "    ) for idx, cell in enumerate(cells))\n",
    "\n",
    "    # Fill the grid with the results\n",
    "    for i, j, value in results:\n",
    "        grid[i, j] = value\n",
    "\n",
    "    # Return the grid and category mapping for this feature\n",
    "    return (f\"{filename_prefix}_{feature_column}\", grid, category_to_int)\n",
    "\n",
    "def geojson_to_numpy_grid_3d_batch(\n",
    "    grid_size: Tuple[int, int],  # Grid size for the output array\n",
    "    target_crs: str = \"EPSG:3857\"  # Web Mercator projection\n",
    ") -> Tuple[np.ndarray, Dict[str, np.ndarray], Dict[str, Dict[Any, int]], List[Dict[str, Any]]]:\n",
    "    # Open a file selection dialog for the user to select multiple GeoJSON files\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "    # Open the file selection dialog\n",
    "    geojson_files = askopenfilenames(\n",
    "        title=\"Select GeoJSON Files\",\n",
    "        filetypes=[(\"GeoJSON files\", \"*.geojson\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "\n",
    "    all_feature_grids = {}\n",
    "    all_feature_mappings = {}\n",
    "    geospatial_info_list = []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for geojson_file in geojson_files:\n",
    "        # Read the GeoJSON file to get the total bounds\n",
    "        gdf = gpd.read_file(geojson_file)\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "        minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "        # Create a fixed-size grid\n",
    "        x = np.linspace(minx, maxx, grid_size[1] + 1)\n",
    "        y = np.linspace(miny, maxy, grid_size[0] + 1)\n",
    "\n",
    "        # Automatically extract all relevant feature columns, excluding geometry columns\n",
    "        feature_columns = [col for col in gdf.columns if col != gdf.geometry.name]\n",
    "\n",
    "        # Get the filename without extension for prefixing\n",
    "        filename_prefix = os.path.splitext(os.path.basename(geojson_file))[0]\n",
    "\n",
    "        # Store geospatial information for each file\n",
    "        geospatial_info = {\n",
    "            'transform': (minx, miny, maxx, maxy),\n",
    "            'crs': target_crs,\n",
    "            'file_name': filename_prefix\n",
    "        }\n",
    "        geospatial_info_list.append(geospatial_info)\n",
    "\n",
    "        # Use joblib to parallelize the processing of each feature column\n",
    "        results.extend(Parallel(n_jobs=-1)(delayed(process_feature_column)(\n",
    "            geojson_file, feature_column, grid_size, target_crs, filename_prefix, x, y\n",
    "        ) for feature_column in feature_columns))\n",
    "\n",
    "    # Process results to merge grids and mappings\n",
    "    for feature_name, grid, category_to_int in results:\n",
    "        all_feature_grids[feature_name] = grid\n",
    "        all_feature_mappings[feature_name] = category_to_int\n",
    "\n",
    "    # Stack all grids into a 3D array\n",
    "    grid_3d = np.stack(list(all_feature_grids.values()), axis=0)\n",
    "\n",
    "    return grid_3d, all_feature_grids, all_feature_mappings, geospatial_info_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARALLEL PROCESSING - CPU - HYBRID - FEATURE SELECTION ENABLED (broken in ipynb)\n",
    "\n",
    "# Function to prompt the user to select features using tkinter\n",
    "def select_features(gdf_dict):\n",
    "    \"\"\"\n",
    "    Create a tkinter GUI window to allow the user to select which features to process.\n",
    "    \"\"\"\n",
    "    selected_features = {}\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "\n",
    "    # Function to create the selection window\n",
    "    def create_selection_window():\n",
    "        selection_window = Toplevel(root)\n",
    "        selection_window.title(\"Select Features to Process\")\n",
    "\n",
    "        # Store variables for checkboxes\n",
    "        feature_vars = {}\n",
    "\n",
    "        # Create checkboxes for each file and its features\n",
    "        for geojson_file, gdf in gdf_dict.items():\n",
    "            feature_columns = [col for col in gdf.columns if col != gdf.geometry.name]\n",
    "\n",
    "            # Extract just the file name from the full path\n",
    "            file_name = os.path.basename(geojson_file)\n",
    "\n",
    "            # Add a frame for each file\n",
    "            frame = Label(selection_window, text=f\"File: {file_name}\")\n",
    "            frame.pack(anchor='w', padx=10, pady=5)\n",
    "\n",
    "            # Create checkboxes for each feature in the file\n",
    "            feature_vars[geojson_file] = {}\n",
    "            for feature in feature_columns:\n",
    "                var = IntVar()\n",
    "                checkbutton = Checkbutton(selection_window, text=feature, variable=var)\n",
    "                checkbutton.pack(anchor='w')\n",
    "                feature_vars[geojson_file][feature] = var\n",
    "\n",
    "        # Function to handle \"OK\" button click\n",
    "        def on_ok():\n",
    "            for geojson_file, features in feature_vars.items():\n",
    "                selected_features[geojson_file] = [feature for feature, var in features.items() if var.get() == 1]\n",
    "            print(\"Selected Features Debugging:\", selected_features)  # Debugging: print selected features\n",
    "            if all(not features for features in selected_features.values()):\n",
    "                print(\"No features were selected.\")  # Debugging: Check if no features were selected\n",
    "            selection_window.destroy()\n",
    "            root.quit()  # Properly close the Tkinter main loop\n",
    "\n",
    "        # Add an \"OK\" button\n",
    "        Button(selection_window, text=\"OK\", command=on_ok).pack(pady=10)\n",
    "\n",
    "        selection_window.mainloop()\n",
    "\n",
    "    create_selection_window()\n",
    "    root.destroy()  # Ensure the root window is properly destroyed\n",
    "    print(\"Final Selected Features Debugging:\", selected_features)  # Debugging: print final selected features\n",
    "    return selected_features\n",
    "\n",
    "# Function to process cells in chunks\n",
    "def process_chunk(chunk, gdf, sindex, feature_column, category_to_int, filename_prefix):\n",
    "    results = []\n",
    "    for idx, cell in chunk:\n",
    "        i, j = divmod(idx, grid_size[1])\n",
    "        possible_matches_index = list(sindex.intersection(cell.bounds))\n",
    "        if not possible_matches_index:\n",
    "            results.append((i, j, np.nan))\n",
    "            continue\n",
    "\n",
    "        possible_matches = gdf.iloc[possible_matches_index]\n",
    "        if possible_matches.empty:\n",
    "            results.append((i, j, np.nan))\n",
    "            continue\n",
    "\n",
    "        intersections = possible_matches.geometry.intersection(cell)\n",
    "        valid_intersections = intersections[intersections.area > 0]\n",
    "\n",
    "        if valid_intersections.empty:\n",
    "            results.append((i, j, np.nan))\n",
    "            continue\n",
    "\n",
    "        if len(valid_intersections) > 5:\n",
    "            areas_per_category = {}\n",
    "            for idx, intersection in enumerate(valid_intersections):\n",
    "                if not intersection.is_empty:\n",
    "                    category = possible_matches.iloc[idx][feature_column]\n",
    "                    category_key = f\"{filename_prefix}_{category}\"\n",
    "                    if category_key not in areas_per_category:\n",
    "                        areas_per_category[category_key] = 0\n",
    "                    areas_per_category[category_key] += intersection.area\n",
    "\n",
    "            if areas_per_category:\n",
    "                max_category = max(areas_per_category, key=areas_per_category.get)\n",
    "                results.append((i, j, category_to_int[max_category]))\n",
    "            else:\n",
    "                results.append((i, j, np.nan))\n",
    "        else:\n",
    "            largest_intersection_idx = valid_intersections.area.idxmax()\n",
    "            category = possible_matches.loc[largest_intersection_idx, feature_column]\n",
    "            results.append((i, j, category_to_int[f\"{filename_prefix}_{category}\"]))\n",
    "    return results\n",
    "\n",
    "# Function to process each feature column\n",
    "def process_feature_column(gdf, feature_column, grid_size, target_crs, filename_prefix, x, y):\n",
    "    gdf = gdf.to_crs(target_crs)\n",
    "\n",
    "    unique_categories = gdf[feature_column].unique()\n",
    "    category_to_int = {f\"{filename_prefix}_{cat}\": i for i, cat in enumerate(unique_categories)}\n",
    "\n",
    "    grid = np.full(grid_size, np.nan)\n",
    "\n",
    "    sindex = gdf.sindex\n",
    "\n",
    "    cells = [(idx, box(x[j], y[i], x[j + 1], y[i + 1]))\n",
    "             for idx, (i, j) in enumerate(np.ndindex(grid_size))]\n",
    "\n",
    "    chunk_size = max(1, len(cells) // 10)\n",
    "    chunks = [cells[i:i + chunk_size] for i in range(0, len(cells), chunk_size)]\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(delayed(process_chunk)(\n",
    "        chunk, gdf, sindex, feature_column, category_to_int, filename_prefix\n",
    "    ) for chunk in chunks)\n",
    "\n",
    "    for result in results:\n",
    "        for i, j, value in result:\n",
    "            grid[i, j] = value\n",
    "\n",
    "    return (f\"{filename_prefix}_{feature_column}\", grid, category_to_int)\n",
    "\n",
    "# Main function\n",
    "def geojson_to_numpy_grid_3d_batch(\n",
    "    grid_size: Tuple[int, int],  # Grid size for the output array\n",
    "    target_crs: str = \"EPSG:3857\"  # Web Mercator projection\n",
    ") -> Tuple[np.ndarray, Dict[str, np.ndarray], Dict[str, Dict[Any, int]], List[Dict[str, Any]]]:\n",
    "    # Use tkinter to select files\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.attributes(\"-topmost\", True)  # Bring the dialog to the front\n",
    "    geojson_files = filedialog.askopenfilenames(\n",
    "        title=\"Select GeoJSON Files\",\n",
    "        filetypes=[(\"GeoJSON files\", \"*.geojson\"), (\"All files\", \"*.*\")]\n",
    "    )\n",
    "    root.destroy()\n",
    "\n",
    "    if not geojson_files:\n",
    "        raise ValueError(\"No files selected. Please select at least one GeoJSON file.\")\n",
    "\n",
    "    # Load all selected files into GeoDataFrames\n",
    "    gdf_dict = {geojson_file: gpd.read_file(geojson_file) for geojson_file in geojson_files}\n",
    "\n",
    "    # Ask the user to select features to process\n",
    "    selected_features = select_features(gdf_dict)\n",
    "\n",
    "    all_feature_grids = {}\n",
    "    all_feature_mappings = {}\n",
    "    geospatial_info_list = []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for geojson_file in geojson_files:\n",
    "        gdf = gdf_dict[geojson_file]\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "        minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "        x = np.linspace(minx, maxx, grid_size[1] + 1)\n",
    "        y = np.linspace(miny, maxy, grid_size[0] + 1)\n",
    "\n",
    "        feature_columns = selected_features.get(geojson_file, [])\n",
    "\n",
    "        if not feature_columns:\n",
    "            print(f\"No features selected for file: {geojson_file}\")\n",
    "            continue\n",
    "\n",
    "        filename_prefix = os.path.splitext(os.path.basename(geojson_file))[0]\n",
    "\n",
    "        geospatial_info = {\n",
    "            'transform': (minx, miny, maxx, maxy),\n",
    "            'crs': target_crs,\n",
    "            'file_name': filename_prefix\n",
    "        }\n",
    "        geospatial_info_list.append(geospatial_info)\n",
    "\n",
    "        results.extend(Parallel(n_jobs=-1)(delayed(process_feature_column)(\n",
    "            gdf, feature_column, grid_size, target_crs, filename_prefix, x, y\n",
    "        ) for feature_column in feature_columns))\n",
    "\n",
    "    for feature_name, grid, category_to_int in results:\n",
    "        all_feature_grids[feature_name] = grid\n",
    "        all_feature_mappings[feature_name] = category_to_int\n",
    "\n",
    "    if not all_feature_grids:\n",
    "        raise ValueError(\"No features were processed. Please select at least one feature to process.\")\n",
    "\n",
    "    grid_3d = np.stack(list(all_feature_grids.values()), axis=0)\n",
    "\n",
    "    return grid_3d, all_feature_grids, all_feature_mappings, geospatial_info_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated grid size: (12, 10)\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE GRID SIZE\n",
    "\n",
    "def compute_grid_size(geojson_file: str, short_edge_cells: int = 1200) -> Tuple[int, int]:\n",
    "    # Read the GeoJSON file\n",
    "    gdf = gpd.read_file(geojson_file)\n",
    "    \n",
    "    # Get the bounding box of the masking region\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    \n",
    "    # Calculate width and height of the bounding box\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    # Determine which is the short and long edge\n",
    "    if width < height:\n",
    "        short_edge = width\n",
    "        long_edge = height\n",
    "        orientation = 'portrait'\n",
    "    else:\n",
    "        short_edge = height\n",
    "        long_edge = width\n",
    "        orientation = 'landscape'\n",
    "\n",
    "    # Compute the aspect ratio\n",
    "    aspect_ratio = long_edge / short_edge\n",
    "\n",
    "    # Compute the number of cells for the long edge\n",
    "    long_edge_cells = int(short_edge_cells * aspect_ratio)\n",
    "\n",
    "    # Determine the grid size based on the orientation\n",
    "    if orientation == 'portrait':\n",
    "        grid_size = (short_edge_cells, long_edge_cells)\n",
    "    else:\n",
    "        grid_size = (long_edge_cells, short_edge_cells)\n",
    "\n",
    "    return grid_size\n",
    "\n",
    "mask_file = r\"C:\\Users\\TyHow\\Documents\\3. Work\\GIS Stuff\\ML_pilot_data\\MASK.geojson\"\n",
    "grid_size = compute_grid_size(mask_file, short_edge_cells=10)[::-1]\n",
    "print(f\"Calculated grid size: {grid_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54f205290c6498f91e14b6bc08902d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='File: geology_clipped.geojson'), Checkbox(value=False, description=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features selected for file: C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No features were processed. Please select at least one feature to process.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#RUN FUNCTION\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#grid_size = (1200, 1550)  # Define the grid size\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m grid_3d, feature_grids, feature_mappings, geospatial_info_list \u001b[38;5;241m=\u001b[39m \u001b[43mgeojson_to_numpy_grid_3d_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of the 3D grid array:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_3d\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[30], line 192\u001b[0m, in \u001b[0;36mgeojson_to_numpy_grid_3d_batch\u001b[1;34m(grid_size, target_crs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     all_feature_mappings[feature_name] \u001b[38;5;241m=\u001b[39m category_to_int\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_feature_grids:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo features were processed. Please select at least one feature to process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    194\u001b[0m grid_3d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mlist\u001b[39m(all_feature_grids\u001b[38;5;241m.\u001b[39mvalues()), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grid_3d, all_feature_grids, all_feature_mappings, geospatial_info_list\n",
      "\u001b[1;31mValueError\u001b[0m: No features were processed. Please select at least one feature to process."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Debugging: {'C:/Users/TyHow/Documents/3. Work/GIS Stuff/ML_pilot_data/geology_clipped.geojson': ['CODIGO', 'DEFINICION', 'GEOCHRON_A']}\n"
     ]
    }
   ],
   "source": [
    "#RUN FUNCTION\n",
    "\n",
    "#grid_size = (1200, 1550)  # Define the grid size\n",
    "\n",
    "# Call the function\n",
    "grid_3d, feature_grids, feature_mappings, geospatial_info_list = geojson_to_numpy_grid_3d_batch(grid_size)\n",
    "\n",
    "# Print results\n",
    "print(\"Shape of the 3D grid array:\", grid_3d.shape)\n",
    "print(\"Feature grids:\", feature_grids.keys())\n",
    "print(\"Feature mappings:\", feature_mappings)\n",
    "print(\"Geospatial information for each file:\", geospatial_info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='7f17d95e-00db-43fc-b4a4-eea4baec9630'>\n",
       "  <div id=\"c75caf97-b9ac-465b-a2ff-23cc512a7e25\" data-root-id=\"7f17d95e-00db-43fc-b4a4-eea4baec9630\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"3e3f7e61-96c5-40ac-ae32-8a1456cec264\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"7f17d95e-00db-43fc-b4a4-eea4baec9630\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"58d85c04-d552-4d8d-80bd-d0059006a559\",\"attributes\":{\"plot_id\":\"7f17d95e-00db-43fc-b4a4-eea4baec9630\",\"comm_id\":\"61e483f8ddca423e87076094a8c878d6\",\"client_comm_id\":\"eb6002762cfc4a88b40714b139b10f3e\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"3e3f7e61-96c5-40ac-ae32-8a1456cec264\",\"roots\":{\"7f17d95e-00db-43fc-b4a4-eea4baec9630\":\"c75caf97-b9ac-465b-a2ff-23cc512a7e25\"},\"root_ids\":[\"7f17d95e-00db-43fc-b4a4-eea4baec9630\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "7f17d95e-00db-43fc-b4a4-eea4baec9630"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Layer 1/2: geology_clipped_fid\n",
      "Min value in layer: 0.0, Max value in layer: 173.0\n",
      "Layer data:\n",
      " [[161. 161. 126. 170. 170. 170. 170. 137.   1.  70.]\n",
      " [161. 163. 117. 170. 121. 170. 137. 137. 172.  63.]\n",
      " [163. 161. 161. 170. 173. 159. 159.  51. 167.  38.]\n",
      " [163. 163. 111. 111. 114.  55. 159.  51.  38.  38.]\n",
      " [105. 105. 111. 151. 159. 159. 159.   1. 110.  46.]\n",
      " [105. 151. 151. 151.   1. 155. 159.  43.  26. 101.]\n",
      " [157. 151. 151. 151. 155.  98. 102.  20. 101. 101.]\n",
      " [ 90. 151. 151.  90.  90.  98. 152.  20.  92.  92.]\n",
      " [ 90.  90.  85.  85.  85. 142. 142.  14.  88.  89.]\n",
      " [ 82.  82.  82.  82.  90. 142.   3.   9.   3. 144.]\n",
      " [ 82.  82. 138. 138. 138.   7.   0.   3. 141. 140.]\n",
      " [ 82.  82.  82. 138. 138. 138.   0.   0.   0.   0.]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85346f3ffcd4adaafbcd27e405aa9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'b68800e6-e979-4e43-abaf-58a7a1521551': {'versionâ€¦"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting Layer 2/2: possible_anomalies_clipped_fid\n",
      "Min value in layer: nan, Max value in layer: nan\n",
      "Layer data:\n",
      " [[nan nan nan nan nan nan nan nan nan  0.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan 20. 20. nan nan nan nan nan  5.  5.]\n",
      " [20. 20. 20. nan 13. 13. nan nan nan nan]\n",
      " [20. nan nan nan 13. 13. nan nan  9. nan]\n",
      " [nan nan nan nan nan 13. nan  7.  6. nan]\n",
      " [nan nan nan nan nan 14. nan nan nan nan]\n",
      " [nan nan 17. 16. 16. 19. 10. nan nan nan]\n",
      " [nan nan 17. 17. 18. 18. 21. 11. 11. 11.]\n",
      " [nan nan 17. 17. 18. 15. 21. 11. 11. nan]]\n",
      "Plotting Layer 1/2: geology_clipped_fid\n",
      "Min value in layer: 0.0, Max value in layer: 173.0\n",
      "Layer data:\n",
      " [[161. 161. 126. 170. 170. 170. 170. 137.   1.  70.]\n",
      " [161. 163. 117. 170. 121. 170. 137. 137. 172.  63.]\n",
      " [163. 161. 161. 170. 173. 159. 159.  51. 167.  38.]\n",
      " [163. 163. 111. 111. 114.  55. 159.  51.  38.  38.]\n",
      " [105. 105. 111. 151. 159. 159. 159.   1. 110.  46.]\n",
      " [105. 151. 151. 151.   1. 155. 159.  43.  26. 101.]\n",
      " [157. 151. 151. 151. 155.  98. 102.  20. 101. 101.]\n",
      " [ 90. 151. 151.  90.  90.  98. 152.  20.  92.  92.]\n",
      " [ 90.  90.  85.  85.  85. 142. 142.  14.  88.  89.]\n",
      " [ 82.  82.  82.  82.  90. 142.   3.   9.   3. 144.]\n",
      " [ 82.  82. 138. 138. 138.   7.   0.   3. 141. 140.]\n",
      " [ 82.  82.  82. 138. 138. 138.   0.   0.   0.   0.]]\n",
      "Plotting Layer 2/2: possible_anomalies_clipped_fid\n",
      "Min value in layer: nan, Max value in layer: nan\n",
      "Layer data:\n",
      " [[nan nan nan nan nan nan nan nan nan  0.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan 20. 20. nan nan nan nan nan  5.  5.]\n",
      " [20. 20. 20. nan 13. 13. nan nan nan nan]\n",
      " [20. nan nan nan 13. 13. nan nan  9. nan]\n",
      " [nan nan nan nan nan 13. nan  7.  6. nan]\n",
      " [nan nan nan nan nan 14. nan nan nan nan]\n",
      " [nan nan 17. 16. 16. 19. 10. nan nan nan]\n",
      " [nan nan 17. 17. 18. 18. 21. 11. 11. 11.]\n",
      " [nan nan 17. 17. 18. 15. 21. 11. 11. nan]]\n",
      "Plotting Layer 1/2: geology_clipped_fid\n",
      "Min value in layer: 0.0, Max value in layer: 173.0\n",
      "Layer data:\n",
      " [[161. 161. 126. 170. 170. 170. 170. 137.   1.  70.]\n",
      " [161. 163. 117. 170. 121. 170. 137. 137. 172.  63.]\n",
      " [163. 161. 161. 170. 173. 159. 159.  51. 167.  38.]\n",
      " [163. 163. 111. 111. 114.  55. 159.  51.  38.  38.]\n",
      " [105. 105. 111. 151. 159. 159. 159.   1. 110.  46.]\n",
      " [105. 151. 151. 151.   1. 155. 159.  43.  26. 101.]\n",
      " [157. 151. 151. 151. 155.  98. 102.  20. 101. 101.]\n",
      " [ 90. 151. 151.  90.  90.  98. 152.  20.  92.  92.]\n",
      " [ 90.  90.  85.  85.  85. 142. 142.  14.  88.  89.]\n",
      " [ 82.  82.  82.  82.  90. 142.   3.   9.   3. 144.]\n",
      " [ 82.  82. 138. 138. 138.   7.   0.   3. 141. 140.]\n",
      " [ 82.  82.  82. 138. 138. 138.   0.   0.   0.   0.]]\n",
      "Plotting Layer 2/2: possible_anomalies_clipped_fid\n",
      "Min value in layer: nan, Max value in layer: nan\n",
      "Layer data:\n",
      " [[nan nan nan nan nan nan nan nan nan  0.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan nan nan nan nan nan nan nan  4.  4.]\n",
      " [nan 20. 20. nan nan nan nan nan  5.  5.]\n",
      " [20. 20. 20. nan 13. 13. nan nan nan nan]\n",
      " [20. nan nan nan 13. 13. nan nan  9. nan]\n",
      " [nan nan nan nan nan 13. nan  7.  6. nan]\n",
      " [nan nan nan nan nan 14. nan nan nan nan]\n",
      " [nan nan 17. 16. 16. 19. 10. nan nan nan]\n",
      " [nan nan 17. 17. 18. 18. 21. 11. 11. 11.]\n",
      " [nan nan 17. 17. 18. 15. 21. 11. 11. nan]]\n"
     ]
    }
   ],
   "source": [
    "#PLOT\n",
    "\n",
    "# Initialize the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Function to plot a specific layer using Matplotlib\n",
    "def plot_layer_bokeh(layer_index):\n",
    "    # Debugging: Print information about the current layer being plotted\n",
    "    print(f\"Plotting Layer {layer_index + 1}/{grid_3d.shape[0]}: {list(feature_grids.keys())[layer_index]}\")\n",
    "    print(f\"Min value in layer: {np.min(grid_3d[layer_index])}, Max value in layer: {np.max(grid_3d[layer_index])}\")\n",
    "\n",
    "    # Create the plot\n",
    "    fig = Figure(figsize=(3, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    im = ax.imshow(grid_3d[layer_index], cmap='tab20', interpolation='nearest', aspect='auto')\n",
    "    ax.set_title(f\"Layer {layer_index + 1}: {list(feature_grids.keys())[layer_index]}\")\n",
    "    fig.colorbar(im, ax=ax, label='Classes')\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "\n",
    "    # Debugging: Display the array data for the current layer\n",
    "    print(\"Layer data:\\n\", grid_3d[layer_index])\n",
    "\n",
    "    return pn.pane.Matplotlib(fig, tight=True)\n",
    "\n",
    "# Create a Panel widget for selecting the layer\n",
    "layer_slider = pn.widgets.IntSlider(name='Layer Index', start=0, end=grid_3d.shape[0] - 1, step=1, value=0)\n",
    "\n",
    "# Bind the plotting function to the slider value\n",
    "panel = pn.bind(plot_layer_bokeh, layer_index=layer_slider)\n",
    "\n",
    "# Display the Panel with the slider and plot\n",
    "pn.Column(layer_slider, panel).servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the array to a file\n",
    "np.save(\"C:\\Users\\TyHow\\Documents\\3. Work\\ML_test_area\\exports\\export_3d.npy\", grid_3d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
